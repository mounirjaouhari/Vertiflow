# üîç DIAGNOSTIC COMPLET - VERTIFLOW DATA PLATFORM
**Date d'analyse :** 01/01/2026  
**Analyste :** GitHub Copilot  
**√âtat global du projet :** ‚ö†Ô∏è **EN CONSTRUCTION** (Infrastructure OK, Pipelines Partiels)

---

## üìä VUE G√âN√âRALE DU PROJET

### Qu'est-ce que VertiFlow ?
**VertiFlow** est une **plateforme de donn√©es industrielle** pour l'**agriculture verticale intelligente**. Elle :
- ‚úÖ Ing√®re **millions de t√©l√©m√©tries** de capteurs IoT (temp√©rature, humidit√©, nutriments, etc.)
- ‚úÖ Valide les donn√©es avec un protocole **Zero-Trust** (sch√©mas JSON strictes)
- ‚úÖ Stocke dans une architecture **hybride** (ClickHouse + MongoDB)
- ‚úÖ Ex√©cute des **mod√®les ML** en temps r√©el (pr√©dictions de r√©colte, optimisations)
- ‚úÖ Expose des **dashboards** (Grafana) et des **APIs**

### Architecture globale
```
Capteurs IoT (MQTT) 
    ‚Üì
Eclipse Mosquitto (MQTT Broker)
    ‚Üì
Apache NiFi (Ingestion & ETL)
    ‚Üì
Apache Kafka (Event Streaming)
    ‚Üì
Cloud Citadel (Python AI Engine)
    ‚Üì
ClickHouse (Telemetry - OLAP) + MongoDB (Configs - Document)
    ‚Üì
Grafana (Dashboards) + APIs (Queries)
```

---

## ‚úÖ CE QUI FONCTIONNE

### Infrastructure Docker (100% pr√™t)
| Service | Port | Statut | V√©rification |
|---------|------|--------|-------------|
| **Zookeeper** | 2181 | ‚úÖ Pr√™t | `docker ps` |
| **Kafka** | 9092/29092 | ‚úÖ Pr√™t | Port 9092 accessible |
| **ClickHouse** | 9000/8123 | ‚úÖ Pr√™t | Base `vertiflow` cr√©√©e |
| **MongoDB** | 27017 | ‚úÖ Pr√™t | Base `vertiflow_ops` cr√©√©e |
| **Mosquitto (MQTT)** | 1883/9001 | ‚úÖ Pr√™t | Broker actif |
| **NiFi** | 8443 | ‚úÖ Pr√™t | HTTPS actif (admin/ctsBtRBKHRAx69EqUghvvgEvjnaLjFEB) |
| **Prometheus** | 9090 | ‚úÖ Pr√™t | M√©triques collect√©es |
| **Grafana** | 3000 | ‚úÖ Pr√™t | admin/admin |

**D√©marrage :** `docker-compose up -d` (+ `docker-compose.metrics.yml` pour monitoring)

### Scripts de Configuration (Partiels)
```
üìÅ infrastructure/init_scripts/
‚îú‚îÄ‚îÄ clickhouse/01_tables.sql          ‚úÖ Cr√©√© (153 colonnes telemetry_raw)
‚îú‚îÄ‚îÄ clickhouse/02_powerbi_views.sql   ‚úÖ Cr√©√© (Vues d'agr√©gation)
‚îú‚îÄ‚îÄ clickhouse/03_external_data.sql   ‚úÖ Cr√©√© (NASA Power, OpenAg)
‚îî‚îÄ‚îÄ mongodb/seed_data.js              ‚úÖ Cr√©√© (Collections + Indices)
```

### Python Core (Cloud Citadel)
```
üìÅ cloud_citadel/
‚îú‚îÄ‚îÄ nervous_system/
‚îÇ   ‚îú‚îÄ‚îÄ oracle.py                 ‚úÖ Pr√©dictions LSTM (mod√®le dummy)
‚îÇ   ‚îú‚îÄ‚îÄ classifier.py             ‚úÖ Classification anomalies
‚îÇ   ‚îú‚îÄ‚îÄ cortex.py                 ‚úÖ Orchestration IA
‚îÇ   ‚îú‚îÄ‚îÄ simulator.py              ‚úÖ Simulation de donn√©es
‚îÇ   ‚îî‚îÄ‚îÄ calibration/agronomic_parameters.yaml  ‚úÖ Config m√©tier
‚îî‚îÄ‚îÄ connectors/
    ‚îú‚îÄ‚îÄ stream_processor.py       ‚úÖ Consumer Kafka
    ‚îî‚îÄ‚îÄ feedback_loop.py          ‚úÖ Boucle feedback
```

---

## ‚ùå CE QUI MANQUE OU EST INCOMPLET

### 1. **Pipelines NiFi non configur√©s**
**Probl√®me :** NiFi tourne mais **aucun flow de donn√©es n'est √©tabli**

**√âtat actuel :**
- NiFi accessible √† `https://localhost:8443` (admin/ctsBtRBKHRAx69EqUghvvgEvjnaLjFEB)
- ‚ùå Pas de processeur MQTT ‚Üí NiFi
- ‚ùå Pas de route vers Kafka
- ‚ùå Pas de validateurs de sch√©ma JSON
- ‚ùå Pas de Dead Letter Queue (DLQ) configur√©e

**Impact :** Z√©ro donn√©e ne circule du capteur √† la base de donn√©es

---

### 2. **Sources de donn√©es (test/simulation) manquantes**
**Probl√®me :** Les algorithmes IA n'ont pas de donn√©es √† traiter

**√âtat actuel :**
- Scripts Python existent mais d√©pendent de donn√©es en provenance de Kafka
- Donn√©es externes (NASA Power, OpenAg) non int√©gr√©es dans l'ingestion
- Pas de g√©n√©rateur de donn√©es de test (simulator.py existe mais non lanc√©)

**Fichiers concern√©s :**
- `scripts/download_nasa_power.py` - T√©l√©charge NASA Power ‚Üí fichier local (pas d'int√©gration)
- `scripts/vision_system_simulator.py` - G√©n√®re donn√©es fictives (pas lanc√© en boucle)
- `cloud_citadel/nervous_system/simulator.py` - Simulation IA (pr√™t, pas lanc√©)

---

### 3. **Mod√®les ML incomplets**
**Probl√®me :** Mod√®les IA ref√®rent √† des fichiers `.h5` qui n'existent pas

**√âtat actuel :**
- `oracle.py` cherche `models/lstm_harvest_v1.h5` ‚Üí **INTROUVABLE**
- Fallback sur mod√®le dummy (fonctionne mais pas production-ready)
- Pas de dossier `models/` track√© en Git

**Impacte :** Pr√©dictions de r√©colte = al√©atoire (mod√®le dummy)

---

### 4. **Connectivit√© Kafka incompl√®te**
**Probl√®me :** Kafka est pr√™t, mais aucun producteur ne publie de donn√©es

**√âtat actuel :**
- Kafka en √©coute sur `kafka:29092` (interne Docker) et `localhost:9092` (externe)
- Topics √† cr√©er : `basil_telemetry_full`, `vertiflow.predictions`, etc.
- ‚ùå NiFi ne publie rien (pas de flow configur√©)
- ‚ùå Pas de script producteur de test

---

### 5. **Bases de donn√©es pr√™tes mais vides**
**√âtat actuel :**
- ‚úÖ ClickHouse : Sch√©ma cr√©√© (`smart_farming.basil_ultimate_realtime` - 153 colonnes)
- ‚úÖ MongoDB : Collections cr√©√©es (`live_state`, `incident_logs`, etc.) avec validateurs
- ‚ùå **Z√âRO DONN√âES INS√âR√âES**

**Pourquoi :** Pas de source de donn√©es entrante (voir point 2)

---

## üéØ PLAN D'ACTION EXACT (√Ä FAIRE)

### **PHASE 1 : V√©rifier que Docker tourne (5 min)**
```bash
cd d:\vertiflow-data-platform\vertiflow-data-platform
docker-compose up -d
docker ps
# V√©rifier que 7 services sont "Up"
```

### **PHASE 2 : Configurer NiFi (30 min)**
**Objectif :** √âtablir le flux MQTT ‚Üí NiFi ‚Üí Kafka ‚Üí ClickHouse

1. Acc√©der √† NiFi : `https://localhost:8443`
2. Login : `admin` / `ctsBtRBKHRAx69EqUghvvgEvjnaLjFEB`
3. Cr√©er les processeurs :
   - **ConsumeMQTT** : √âcoute `mosquitto:1883`, topic `#` (tous)
   - **ValidateRecord** : Valide contre sch√©ma JSON (dossier `/docs/schemas`)
   - **PutKafka** : Publie vers topic `basil_telemetry_full`
   - **RoutOnAttribute** : Rejette les invalides vers DLQ
4. Connecter les processeurs en s√©quence
5. Activer le flow

**Ressource :** Scripts existants
- `scripts/setup_nifi_pipeline_v2.py` - √Ä adapter/utiliser

---

### **PHASE 3 : Lancer un g√©n√©rateur de donn√©es (15 min)**
**Objectif :** Alimenter MQTT avec des t√©l√©m√©tries de test

**Option A (Recommand√© - Simulation Python) :**
```bash
python cloud_citadel/nervous_system/simulator.py
# G√©n√®re des messages MQTT + Kafka en boucle
```

**Option B (Script existant) :**
```bash
python scripts/vision_system_simulator.py
```

**V√©rification :** Voir les donn√©es arriver dans ClickHouse
```sql
SELECT COUNT(*) FROM smart_farming.basil_ultimate_realtime;
```

---

### **PHASE 4 : Valider les bases de donn√©es (10 min)**
**Via VSCode (DBCode extension) :**

1. **ClickHouse :**
   - Connexion : Host `localhost`, Port `8123`
   - Test query : `SELECT 1; SHOW TABLES;`
   - V√©rifier : Table `basil_ultimate_realtime` avec ~153 colonnes

2. **MongoDB :**
   - Connexion : `mongodb://localhost:27017/vertiflow_ops`
   - V√©rifier : Collections `live_state`, `incident_logs`
   - Ins√©rer test : `db.live_state.insertOne({...})`

---

### **PHASE 5 : Lancer les algorithmes IA (15 min)**
**Objectif :** Alimenter les pr√©dictions

```bash
# Terminal 1 : Oracle (Pr√©dictions de r√©colte)
python cloud_citadel/nervous_system/oracle.py

# Terminal 2 : Classifier (D√©tection d'anomalies)
python cloud_citadel/nervous_system/classifier.py

# Terminal 3 : Cortex (Orchestration)
python cloud_citadel/nervous_system/cortex.py
```

---

### **PHASE 6 : V√©rifier les dashboards (5 min)**
1. **Grafana** : `http://localhost:3000` (admin/admin)
   - V√©rifier les m√©triques Prometheus
   - Cr√©er des panels sur les donn√©es ClickHouse

2. **ClickHouse HTTP UI** : `http://localhost:8123`
   - Requ√™te de v√©rification : `SELECT COUNT(*) FROM smart_farming.basil_ultimate_realtime;`

---

## üîß V√âRIFICATIONS RAPIDES (√Ä FAIRE MAINTENANT)

### V√©rifier Docker
```powershell
# Terminal
docker ps
docker logs kafka
docker logs clickhouse
docker logs mongodb
```

### V√©rifier ClickHouse
```powershell
# Via terminal ou DBCode
curl http://localhost:8123/?query=SELECT%201
# Doit retourner : 1
```

### V√©rifier MongoDB
```powershell
mongosh mongodb://localhost:27017
use vertiflow_ops
db.live_state.find().limit(1)
```

### V√©rifier Kafka
```powershell
docker exec kafka kafka-topics --bootstrap-server kafka:29092 --list
# Doit lister les topics (ou √™tre vide si aucun cr√©√©)
```

---

## üìã CHECKLIST POUR SUIVRE

- [ ] Docker tourne (7 services)
- [ ] Acc√®s ClickHouse (8123 ou 9000)
- [ ] Acc√®s MongoDB (27017)
- [ ] Acc√®s NiFi (8443)
- [ ] DBCode connect√© aux 2 bases
- [ ] Simulateur de donn√©es lanc√©
- [ ] Donn√©es dans ClickHouse (COUNT > 0)
- [ ] Donn√©es dans MongoDB (live_state > 0)
- [ ] Algorithmes IA lanc√©s (Oracle, Classifier, Cortex)
- [ ] Grafana affiche des m√©triques

---

## üìû QUESTIONS FR√âQUENTES

**Q: Pourquoi aucune donn√©e n'arrive ?**  
A: NiFi n'a pas de flow configur√©. Phase 2 obligatoire.

**Q: Le mod√®le LSTM ne fonctionne pas ?**  
A: Le fichier `models/lstm_harvest_v1.h5` est manquant. Trainer ou utiliser le mod√®le dummy (acceptable en dev).

**Q: Comment int√©grer les donn√©es NASA Power ?**  
A: `scripts/download_nasa_power.py` t√©l√©charge localement. √Ä int√©grer dans NiFi ou le simulateur.

**Q: Comment voir ce qui se passe en temps r√©el ?**  
A: VSCode + DBCode Explorer pour inspecter les tables, ou Kafka UI (√† installer si besoin).

---

**üéØ PROCHAINE √âTAPE :** V√©rifier Docker, puis je te guide pour configurer NiFi.
