üöÄ Guide de D√©marrage Complet - Projet VertiFlow

Plateforme d'Intelligence Artificielle pour l'Agriculture Verticale

Ce guide vous accompagne de z√©ro jusqu'√† une production compl√®te, en utilisant l'infrastructure Docker, les pipelines NiFi, les bases de donn√©es ClickHouse/MongoDB et les algorithmes d'IA.

üìã Pr√©-requis Techniques

Avant de commencer, assurez-vous d'avoir :

Docker Desktop (ou Docker Engine + Docker Compose) install√© et lanc√©.

Minimum : 4 CPU, 8 Go RAM allou√©s √† Docker.

Python 3.9+ install√©.

Git pour cloner le d√©p√¥t.

Acc√®s internet (pour t√©l√©charger les images Docker et les libs Python).

üèóÔ∏è Phase 1 : Lancement de l'Infrastructure (Socle)

C'est la fondation. Nous allons lancer tous les serveurs (Kafka, NiFi, bases de donn√©es).

Ouvrez un terminal √† la racine du projet vertiflow-data-platform/.

Lancez la stack principale :

docker-compose up -d


Attendez ~2 minutes que tous les conteneurs soient "Healthy" (surtout NiFi et ClickHouse).

Lancez la stack de monitoring (Optionnel mais recommand√©) :

docker-compose -f infra/docker-compose.metrics.yml up -d


V√©rifiez que vous avez acc√®s √† :

NiFi : https://localhost:8443/nifi (Attendez quelques minutes)

Grafana : http://localhost:3000 (Login: admin/admin)

üì¶ Phase 2 : Initialisation des Donn√©es

Maintenant que les serveurs tournent, nous devons cr√©er les tables, les topics et les indexes.

Installez les d√©pendances Python :

pip install -r requirements.txt


Ex√©cutez le script ma√Ætre d'initialisation :

python infrastructure/init_infrastructure.py


Ce que √ßa fait :

V√©rifie que Kafka, Mongo et ClickHouse r√©pondent.

Cr√©e le topic Kafka basil_telemetry_full.

Cr√©e la base smart_farming dans ClickHouse.

Injecte les recettes de culture (plant_recipes) dans MongoDB.

Succ√®s attendu : Des coches vertes ‚úÖ partout dans le terminal.

V√©rifiez la cr√©ation des tables ClickHouse (Optionnel) :

Connectez-vous au conteneur ClickHouse ou utilisez un client DBeaver.

V√©rifiez que la table smart_farming.basil_ultimate_realtime existe (elle est cr√©√©e par le montage Docker des scripts .sql au d√©marrage).

üîÑ Phase 3 : Construction de l'Usine NiFi (ETL)

C'est le moment de c√¢bler le traitement des donn√©es.

Assurez-vous que le driver ClickHouse est en place :

Le fichier clickhouse-jdbc-0.4.6.jar doit √™tre dans le dossier drivers/ √† la racine du projet.

Lancez le d√©ploiement automatique du pipeline :

python scripts/setup_nifi_pipeline.py


Ce que √ßa fait :

Se connecte √† l'API NiFi.

Cr√©e les 4 zones (Collection, Fusion, Qualit√©, Publication).

Configure la connexion MQTT, Kafka et ClickHouse.

Active les contr√¥leurs services.

Note : Si le script √©choue (SSL error), attendez encore 1 minute que NiFi finisse son boot.

D√©marrez les processeurs :

Allez sur https://localhost:8443/nifi.

Faites un clic droit sur le groupe principal "VERTIFLOW_DATA_PLATFORM_V1" -> Start.

üì° Phase 4 : Injection de Donn√©es (Simulation)

Le syst√®me est pr√™t mais vide. Injectons de la vie !

Lancez le Simulateur IoT (Le c≈ìur du syst√®me) :
Ouvrez un nouveau terminal et lancez :

python scripts/simulators/iot_sensor_simulator.py


Vous verrez des logs d'envoi MQTT (üì§ [MQTT] ...).

Laissez ce script tourner en fond.

Lancez le Connecteur M√©t√©o (Donn√©es r√©elles) :

python scripts/download_nasa_power.py


Cela va cr√©er un fichier JSON dans data_ingestion/nasa_weather. NiFi le d√©tectera automatiquement.

Simulez la Vision par Ordinateur (Croissance) :

python scripts/simulators/vision_system_simulator.py


üß† Phase 5 : Activation de l'Intelligence Artificielle

Maintenant que les donn√©es coulent, activons les cerveaux.

Lancez l'Oracle (Pr√©diction R√©colte) :

python cloud_citadel/nervous_system/oracle.py


Il va commencer √† √©couter Kafka, faire des pr√©dictions, et renvoyer les r√©sultats dans le topic vertiflow.predictions.

Lancez le Cortex (Optimisation) :

python cloud_citadel/nervous_system/cortex.py


Il va analyser les donn√©es ClickHouse et optimiser les recettes dans MongoDB.

üìä Phase 6 : Visualisation & Pilotage

Tout est en place. Voyons le r√©sultat.

Ouvrez Power BI Desktop.

Connectez-vous √† ClickHouse :

Source : ODBC.

Cha√Æne de connexion : Driver={ClickHouse ODBC Driver (Unicode)};Server=localhost;Port=8123;Database=smart_farming;

Connectez-vous au Streaming (Optionnel) :

Configurez un "Push Dataset" dans l'interface Power BI Service et mettez l'URL API dans le processeur NiFi correspondant (Zone 4).

üÜò D√©pannage (Troubleshooting)

NiFi ne d√©marre pas ?

V√©rifiez la RAM Docker (min 4Go).

docker logs nifi pour voir les erreurs Java.

Pas de donn√©es dans ClickHouse ?

V√©rifiez que le simulateur tourne.

V√©rifiez dans NiFi que les processeurs sont "Running" (Fl√®che verte).

V√©rifiez les logs NiFi pour des erreurs JDBC ("Driver not found" = v√©rifiez le dossier drivers/).

Kafka est lent ?

C'est normal au premier lancement (cr√©ation des fichiers logs).

F√©licitations ! Vous avez maintenant