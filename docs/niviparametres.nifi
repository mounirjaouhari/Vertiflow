ğŸš€ Pipeline ETL NiFi - Architecture VertiFlow

Ce document dÃ©taille la configuration des processeurs et des services de contrÃ´le pour le flux de donnÃ©es de l'agriculture verticale.

ğŸ›  Services de ContrÃ´le (Controller Services)

Avant de crÃ©er les processeurs, configurez ces services globaux :

DBCPConnectionPool (ClickHouse) :

Database Connection URL: jdbc:clickhouse://clickhouse:8123/vertiflow

Database Driver Class Name: com.clickhouse.jdbc.ClickHouseDriver

Database Driver Location(s): /opt/nifi/nifi-current/drivers/clickhouse-jdbc.jar

JsonTreeReader : Pour parser les messages MQTT entrants.

JsonRecordSetWriter : Pour formater les sorties vers Kafka et ClickHouse.

MongoDBControllerService :

Mongo URI: mongodb://mongodb:27017

Database Name: vertiflow

ğŸŒŠ Flux de DonnÃ©es par Zones

Zone 1 : Ingestion & Extraction (MQTT)

ConsumeMQTT :

Broker URI: tcp://mosquitto:1883

Topic Filter: v1/sensors/+/telemetry

RÃ´le : RÃ©cupÃ¨re les donnÃ©es brutes des capteurs ESP32.

Zone 2 : Transformation & Enrichissement (Fusion)

UpdateRecord :

Record Reader/Writer: JSON

OpÃ©ration : Ajout d'un ingestion_timestamp et normalisation des noms de variables (ex: temp -> air_temperature).

LookupRecord (MongoDB) :

Configuration : Utilise la collection system_registry.

RÃ´le : Ajoute les mÃ©tadonnÃ©es de la tour (tower_id, location) en fonction du sensor_id prÃ©sent dans le message.

Zone 3 : Validation Biologique (Le "Cerveau")

LookupRecord (Recipes) :

Configuration : Utilise la collection crop_recipes.

RÃ´le : RÃ©cupÃ¨re les seuils min et max pour la phase actuelle de la plante.

ValidateRecord :

Schema Registry : Compare la valeur du capteur aux seuils rÃ©cupÃ©rÃ©s.

Sortie :

Success -> Vers la publication.

Invalid -> Vers un processeur PublishKafka (Topic: alerts_validation) pour notifier @Asama.

Zone 4 : Publication & Persistance

PublishKafka_2_6 :

Topic Name: basil_telemetry_full

RÃ´le : Diffusion en temps rÃ©el pour le dashboard Grafana.

PutDatabaseRecord (ClickHouse) :

Record Reader: JSON

Table Name: basil_ultimate_realtime

RÃ´le : Stockage historique pour l'analyse de donnÃ©es Ã  long terme.

ğŸ“Š SchÃ©ma de cÃ¢blage logique

[ConsumeMQTT] 
      â”‚
      â–¼ (success)
[UpdateRecord] (Enrichissement Temporel)
      â”‚
      â–¼ (success)
[LookupRecord] (Enrichissement via MongoDB Configs)
      â”‚
      â–¼ (success)
[LookupRecord] (RÃ©cupÃ©ration Seuils Biologiques)
      â”‚
      â–¼ (success)
[ValidateRecord] â”€â”€â”€ (invalid) â”€â”€â–¶ [PublishKafka] (Topic: alerts)
      â”‚
      â–¼ (valid)
   â”Œâ”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â–¼              â–¼
[PublishKafka]  [PutDatabaseRecord]
(Topic: final)  (ClickHouse)
