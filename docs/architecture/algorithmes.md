# GUIDE DES ALGORITHMES - PROJET VERTIFLOW

**Agriculture Verticale Intelligente & Data-Driven**

## üìã Table des Mati√®res

1. [Introduction](https://www.google.com/search?q=%23introduction)
2. [Cartographie des Algorithmes](https://www.google.com/search?q=%23cartographie-des-algorithmes)
3. [D√©tail des Algorithmes & Impl√©mentation](https://www.google.com/search?q=%23d√©tail-des-algorithmes--impl√©mentation)
   - [Phase 1 : Hygi√®ne & Qualit√© (NiFi)](https://www.google.com/search?q=%23phase-1--hygi√®ne--qualit√©-nifi)
   - [Phase 2 : Survie & Contr√¥le (MongoDB)](https://www.google.com/search?q=%23phase-2--survie--contr√¥le-mongodb)
   - [Phase 3 : Analyse Scientifique (ClickHouse)](https://www.google.com/search?q=%23phase-3--analyse-scientifique-clickhouse)
   - [Phase 4 : Intelligence Pr√©dictive (Python/ML)](https://www.google.com/search?q=%23phase-4--intelligence-pr√©dictive-pythonml)

## 1. Introduction

Ce document d√©taille les **11 Algorithmes Scientifiques** qui constituent le "Cerveau Num√©rique" de la plateforme VertiFlow. Chaque algorithme r√©pond √† un besoin pr√©cis de l'√©tude scientifique : **Fiabilit√©**, **Survie**, **Compr√©hension** et **Pr√©diction**.

## 2. Cartographie des Algorithmes

| **ID**  | **Nom de l'Algorithme**          | **Type**      | **Emplacement** | **R√¥le Scientifique**                    |
| ------- | -------------------------------- | ------------- | --------------- | ---------------------------------------- |
| **A1**  | Normalisation JSON               | ETL           | NiFi            | Standardisation des formats h√©t√©rog√®nes. |
| **A2**  | D√©tection d'Aberration (Z-Score) | Statistique   | NiFi            | Rejet des donn√©es capteurs d√©faillants.  |
| **A3**  | Enrichissement Contextuel        | Fusion        | NiFi            | Ajout des m√©tadonn√©es l√©gales (Bail).    |
| **A4**  | Seuillage (Thresholding)         | Logique       | MongoDB         | Comparaison Temps R√©el vs Cibles Expert. |
| **A5**  | R√®gles M√©tier (Rule Engine)      | Bool√©en       | MongoDB         | Actions r√©flexes (Arr√™t Urgence).        |
| **A6**  | Agr√©gation Temporelle            | SQL           | ClickHouse      | R√©duction du bruit (Moyennes horaires).  |
| **A7**  | Corr√©lation (Pearson)            | SQL           | ClickHouse      | Preuve des liens (Lumi√®re vs Poids).     |
| **A8**  | Segmentation (ANOVA)             | SQL           | ClickHouse      | Comparaison A/B Testing (Racks).         |
| **A9**  | S√©ries Temporelles (LSTM)        | Deep Learning | Python (Oracle) | Pr√©diction date de r√©colte.              |
| **A10** | Classification (Random Forest)   | ML Supervis√©  | Python (Oracle) | Pr√©diction qualit√© (Premium/Standard).   |
| **A11** | Optimisation (Gradient Descent)  | Math          | Python (Cortex) | Recherche de la recette id√©ale.          |

## 3. D√©tail des Algorithmes & Impl√©mentation

### Phase 1 : Hygi√®ne & Qualit√© (NiFi)

#### ‚öôÔ∏è Algorithme A2 : D√©tection d'Aberration (Z-Score)

- **Ticket :** `TICKET-020`
- **Emplacement :** NiFi (Processeur `ExecuteScript` - Groovy/Python)
- **Objectif :** Garantir que l'√©tude ne se base pas sur des donn√©es fausses. Si une valeur est √† plus de 3 √©carts-types de la moyenne glissante, elle est marqu√©e comme suspecte.

```
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
================================================================================
ALGORITHME A2 : Z-SCORE OUTLIER DETECTION
================================================================================
Projet              : VertiFlow
Ticket              : TICKET-020
Responsable         : @Mouhammed (Data Engineer)
Emplacement         : NiFi / Zone 2 / Groupe Validation
Type                : Script Python (Jython) pour ExecuteScript Processor

DESCRIPTION SCIENTIFIQUE:
Impl√©mente le test de Z-Score pour filtrer les anomalies statistiques en temps r√©el.
Z = (X - Œº) / œÉ
Si |Z| > 3, la donn√©e est consid√©r√©e comme une erreur de capteur (99.7% confiance).

ENTR√âES:
    - flowFile (JSON): { "temp_c": 24.5, "sensor_id": "S1", ... }
    - State Manager: Stocke Œº (moyenne) et œÉ (√©cart-type) par capteur.

SORTIES:
    - Attribut 'data_integrity_flag': 'VALID' ou 'INVALID_OUTLIER'
================================================================================
"""

import json
import math
from org.apache.commons.io import IOUtils
from java.nio.charset import StandardCharsets
from org.apache.nifi.processor.io import StreamCallback

class ZScoreFilter(StreamCallback):
    def __init__(self):
        pass

    def process(self, inputStream, outputStream):
        text = IOUtils.toString(inputStream, StandardCharsets.UTF_8)
        record = json.loads(text)
        
        # --- PARAM√àTRES SCIENTIFIQUES (Calibr√©s par @Asama) ---
        # Dans un vrai cas, ces valeurs viendraient du State Manager (Cache)
        # Exemple pour la Temp√©rature (¬∞C)
        MEAN_TEMP = 24.0  # Moyenne historique
        STD_DEV_TEMP = 2.5 # √âcart-type tol√©r√©
        THRESHOLD = 3.0   # Seuil de rejet (Sigma)

        val = record.get('air_temp_internal')
        
        status = "VALID"
        z_score = 0.0

        if val is not None:
            try:
                float_val = float(val)
                # Calcul du Z-Score
                z_score = (float_val - MEAN_TEMP) / STD_DEV_TEMP
                
                if abs(z_score) > THRESHOLD:
                    status = "INVALID_OUTLIER"
                    # On ne rejette pas le flowfile, on le marque pour analyse
                    record['anomaly_confidence_score'] = 1.0 # 100% anomalie
                else:
                    record['anomaly_confidence_score'] = 0.0
                    
                record['z_score_temp'] = round(z_score, 2)
                
            except ValueError:
                status = "ERROR_TYPE"

        # Mise √† jour du flag de qualit√© (Col 150)
        record['data_integrity_flag'] = status
        
        outputStream.write(json.dumps(record).encode('utf-8'))

flowFile = session.get()
if flowFile is not None:
    # Lecture & √âcriture
    callback = ZScoreFilter()
    flowFile = session.write(flowFile, callback)
    
    # Lecture du status pour le routage NiFi
    # On lit le contenu pour extraire le flag (simplification pour l'exemple)
    # En prod, on utiliserait un attribut d√©di√©.
    session.transfer(flowFile, REL_SUCCESS)
```

### Phase 2 : Survie & Contr√¥le (MongoDB)

#### üõ°Ô∏è Algorithme A4 : Seuillage & Alerte (Thresholding)

- **Ticket :** `TICKET-021`
- **Emplacement :** MongoDB (Trigger / Change Stream) ou Microservice Node.js
- **Objectif :** Prot√©ger l'actif biologique. Compare la valeur entrante aux bornes d√©finies par l'agronome.

```
/**
 * ================================================================================
 * ALGORITHME A4 : DYNAMIC THRESHOLDING (SURVIE)
 * ================================================================================
 * Projet              : VertiFlow
 * Ticket              : TICKET-021
 * Responsable         : @Asama (Biologiste) & @Imrane (DevOps)
 * Emplacement         : Cloud Citadel / Microservice Cortex
 * Type                : JavaScript (Node.js Logic)
 *
 * DESCRIPTION SCIENTIFIQUE:
 * Compare les m√©triques temps r√©el aux "Cibles R√©f√©rentielles" (Colonnes 131-145).
 * Applique la Loi de Liebig (Facteur limitant) : Si un seul nutriment est critique,
 * l'alerte est maximale.
 *
 * ENTR√âES:
 * - Telemetry Document (Kafka Stream)
 *
 * SORTIES:
 * - Alert Object (envoy√© √† Power BI & Slack)
 * - Commande MQTT (Arr√™t pompe)
 * ================================================================================
 */

function checkVitalSigns(telemetryData) {
    const alerts = [];
    const nutrients = telemetryData.nutrition; // Bloc II
    const targets = telemetryData.targets;     // Bloc XI (Cibles Expert)

    // 1. V√©rification Azote (Nutrient N)
    // Tol√©rance : +/- 10% de la cible
    const n_min = targets.ref_n_target * 0.90;
    const n_max = targets.ref_n_target * 1.10;

    if (nutrients.nutrient_n_total < n_min) {
        alerts.push({
            level: "CRITICAL",
            code: "N_DEFICIENCY",
            message: `Carence Azote d√©tect√©e: ${nutrients.nutrient_n_total} ppm (Cible > ${n_min})`,
            action: "INJECT_N_SOLUTION" // Ordre pour l'automate
        });
    }

    // 2. V√©rification VPD (Vapor Pressure Deficit) - Moteur de transpiration
    // Cible : 0.8 - 1.2 kPa
    const vpd = telemetryData.environment.vapor_pressure_deficit;
    
    if (vpd > 1.5) {
        alerts.push({
            level: "WARNING",
            code: "HIGH_VPD_STRESS",
            message: `Stress hydrique (VPD √©lev√©): ${vpd} kPa. Risque fermeture stomates.`,
            action: "ACTIVATE_MISTING" // Ordre brumisation
        });
    } else if (vpd < 0.4) {
        alerts.push({
            level: "WARNING",
            code: "LOW_VPD_RISK",
            message: `VPD trop bas: ${vpd} kPa. Risque fongique (Botrytis).`,
            action: "INCREASE_VENTILATION" // Ordre ventilateurs
        });
    }

    return {
        hasAlerts: alerts.length > 0,
        alerts: alerts,
        timestamp: new Date()
    };
}
```

### Phase 3 : Analyse Scientifique (ClickHouse)

#### üìä Algorithme A7 : Corr√©lation de Pearson

- **Ticket :** `TICKET-022`
- **Emplacement :** ClickHouse (Vue Mat√©rialis√©e SQL)
- **Objectif :** Prouver les hypoth√®ses scientifiques. "Est-ce que l'ajout de lumi√®re augmente vraiment la biomasse pour CETTE vari√©t√© ?"

```
/*
================================================================================
ALGORITHME A7 : MATRICE DE CORR√âLATION (PEARSON)
================================================================================
Projet              : VertiFlow
Ticket              : TICKET-022
Responsable         : @Mounir (Architecte / Scientifique)
Emplacement         : ClickHouse / Init Scripts
Type                : SQL (Analytical Query)

DESCRIPTION SCIENTIFIQUE:
Calcule le coefficient de corr√©lation (r) entre les facteurs environnementaux (X)
et les r√©sultats de croissance (Y).
-1 <= r <= 1.
Si r > 0.8 : Forte corr√©lation positive (Preuve valid√©e).

REQU√äTE:
Analyse sur les 30 derniers jours, agr√©g√©e par Vari√©t√© de Basilic.
================================================================================
*/

CREATE OR REPLACE VIEW smart_farming.view_algo_7_correlation AS
SELECT
    species_variety,
    
    -- Corr√©lation 1 : Lumi√®re (DLI) vs Poids (Biomasse)
    -- Hypoth√®se : + de lumi√®re = + de poids
    corr(light_dli_accumulated, fresh_biomass_est) AS r_light_growth,
    
    -- Corr√©lation 2 : Temp√©rature vs Qualit√© (Huiles)
    -- Hypoth√®se : Temp√©rature trop haute d√©truit les ar√¥mes
    corr(air_temp_internal, essential_oil_yield) AS r_temp_quality,
    
    -- Corr√©lation 3 : CO2 vs Vitesse de Croissance (RGR)
    corr(co2_level_ambient, relative_growth_rate) AS r_co2_speed,
    
    -- M√©triques de fiabilit√© statistique
    count() AS sample_size,
    bar(r_light_growth, -1, 1, 50) AS viz_bar_light -- Visualisation ASCII dans la console

FROM smart_farming.basil_ultimate_realtime
WHERE 
    timestamp > now() - INTERVAL 30 DAY
    AND data_integrity_flag = 0 -- Uniquement donn√©es valides (Algo A2)
GROUP BY 
    species_variety
ORDER BY 
    species_variety;
```

### Phase 4 : Intelligence Pr√©dictive (Python/ML)

#### üîÆ Algorithme A9 : Pr√©diction de R√©colte (LSTM)

- **Ticket :** `TICKET-023`
- **Emplacement :** Cloud Citadel / `oracle.py`
- **Objectif :** Pr√©dire la date exacte de r√©colte (`expected_harvest_date`) en analysant la courbe temporelle de croissance. Permet d'optimiser la logistique de vente.

```
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
================================================================================
ALGORITHME A9 : LSTM HARVEST PREDICTOR
================================================================================
Projet              : VertiFlow
Ticket              : TICKET-023
Responsable         : @Mounir (Scientifique) & @Mouhammed (Data)
Emplacement         : cloud_citadel/nervous_system/oracle.py
Type                : Python (TensorFlow/Keras)

DESCRIPTION SCIENTIFIQUE:
Utilise un r√©seau de neurones r√©currents (LSTM - Long Short-Term Memory) pour
mod√©liser la dynamique non-lin√©aire de la croissance du basilic.
Le mod√®le prend en entr√©e une s√©quence de 7 jours (T, H, PAR, CO2) et pr√©dit
le 'fresh_biomass_est' √† J+7.
Si Biomasse > Target, alors Date R√©colte = Date actuelle + Jours pr√©dits.

ENTR√âES:
    - S√©quence temporelle (n_samples, 7 jours, 5 features)
    - Features: [air_temp, ppfd, vpd, co2, current_biomass]

SORTIES:
    - Pr√©diction: { "rack_id": "R1", "days_to_harvest": 4.5, "confidence": 0.92 }
================================================================================
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

class HarvestOracle:
    def __init__(self):
        self.model = self._build_model()
        
    def _build_model(self):
        """Construction de l'architecture neuronale."""
        model = Sequential()
        # Couche LSTM capable de retenir les d√©pendances temporelles (m√©moire de la plante)
        model.add(LSTM(units=50, return_sequences=True, input_shape=(7, 5)))
        model.add(Dropout(0.2)) # Pr√©vention du sur-apprentissage
        model.add(LSTM(units=50, return_sequences=False))
        model.add(Dropout(0.2))
        
        # Couche de sortie : Pr√©diction de la biomasse (R√©gression)
        model.add(Dense(units=1)) 
        
        model.compile(optimizer='adam', loss='mean_squared_error')
        return model

    def predict_harvest_date(self, time_series_data, target_weight):
        """
        Calcule les jours restants avant r√©colte.
        
        :param time_series_data: Array (1, 7, 5) - Donn√©es des 7 derniers jours
        :param target_weight: Float - Poids cible (ex: 50g)
        """
        # 1. Pr√©diction de la croissance future (Simulation J+1, J+2...)
        current_weight = time_series_data[0, -1, 4] # Dernier poids connu
        days_remaining = 0
        predicted_weight = current_weight
        
        # Simulation it√©rative simplifi√©e pour l'exemple
        # (Dans la r√©alit√©, on pr√©dit la s√©quence compl√®te)
        while predicted_weight < target_weight and days_remaining < 30:
            growth_step = self.model.predict(time_series_data, verbose=0)
            predicted_weight += growth_step[0][0]
            days_remaining += 1
            
            # Mise √† jour glissante de la fen√™tre temporelle pour le pas suivant
            # (On suppose des conditions stables pour la simulation)
            
        return {
            "days_remaining": days_remaining,
            "predicted_final_biomass": float(predicted_weight),
            "status": "OPTIMAL" if days_remaining < 15 else "SLOW_GROWTH"
        }

# Exemple d'utilisation (Mock)
if __name__ == "__main__":
    oracle = HarvestOracle()
    print("üß† Oracle LSTM initialis√©. Pr√™t pour l'inf√©rence.")
    # data = get_data_from_clickhouse(...)
    # res = oracle.predict_harvest_date(data, 50.0)
```

### Conclusion

Ce document rassemble la logique intellectuelle de votre projet.

- **NiFi (A2)** filtre le bruit.
- **MongoDB (A4)** prot√®ge la vie.
- **ClickHouse (A7)** valide la science.
- **Python (A9)** anticipe le march√©.

C'est cette synergie qui fait de VertiFlow une plateforme unique.