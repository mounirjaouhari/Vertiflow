<div align="center">

<!-- Logo et titre principal -->
<img src="images/versiflow.PNG" alt="VertiFlow Logo" width="800"/>

# ğŸŒ± VertiFlow

### **Plateforme Data pour l'Agriculture Verticale Intelligente**

<br/>

---

## ğŸ“ PROJET DE FIN DE FORMATION DATA ENGINEERING

**RÃ©alisÃ© par l'Ã©quipe DATAFLOW**

---

<br/>

<img src="images/unnamed.jpg" alt="Digital Agriculture" width="600"/>

<br/>

> **Programme JobInTech** â€” Initiative nationale portÃ©e par le **MinistÃ¨re de la Transition NumÃ©rique et de la RÃ©forme de l'Administration (MTNRA)**, en partenariat avec le **Groupe CDG**, et opÃ©rÃ© par **Maroc Numeric Cluster (MNC)**.
>
> Formation dispensÃ©e Ã  **YNOV Maroc Campus**

<br/>

[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-24.0+-blue.svg)](https://www.docker.com/)
[![Status](https://img.shields.io/badge/status-development-yellow.svg)](CHANGELOG.md)
[![NiFi](https://img.shields.io/badge/Apache%20NiFi-1.23+-728E9B.svg)](https://nifi.apache.org/)
[![ClickHouse](https://img.shields.io/badge/ClickHouse-23.8+-FFCC00.svg)](https://clickhouse.com/)

**TÃ©lÃ©mÃ©trie IoT temps rÃ©el | Automatisation ML | Validation Zero-Trust | RÃ©silience Enterprise**

[ğŸš€ DÃ©marrage](#-dÃ©marrage-rapide) â€¢ [ğŸ—ï¸ Architecture](#-architecture) â€¢ [ğŸ¤– Intelligence](#-intelligence-artificielle) â€¢ [ğŸ“Š Diagrammes](#-diagrammes) â€¢ [ğŸŒ¿ Agri-Copilot Pro](#-agri-copilot-pro)

</div>

---

## ğŸ“‹ Informations du Projet

| Attribut | Valeur |
|----------|--------|
| **Date de crÃ©ation** | 25/12/2025 |
| **Ã‰quipe** | DATAFLOW |
| **Formation** | Data Engineering - JobInTech |
| **Ã‰cole** | YNOV Maroc Campus |
| **RÃ©fÃ©rent** | @MrZakaria |

### ğŸ‘¥ Membres de l'Ã‰quipe

| RÃ´le | Membre | ResponsabilitÃ© |
|------|--------|----------------|
| ğŸ—ï¸ Architecte & Data Scientist | **@Mounir** | Conception systÃ¨me, ModÃ¨les ML, Bio-physique |
| âš™ï¸ DevOps & Infrastructure | **@Imrane** | Docker, CI/CD, Monitoring |
| ğŸ“Š Data Engineer | **@Mouhammed** | Pipelines ETL, Kafka, ClickHouse |
| ğŸŒ¿ Biologiste & Expert MÃ©tier | **@Asama** | Calibration agronomique, Validation scientifique |
| ğŸ‘¨â€ğŸ’¼ Tech Lead & Data Architect | **@MrZakaria** | Revue architecture, Gouvernance des donnÃ©es |

---

## ğŸ“‘ Table des MatiÃ¨res

- [ğŸŒ Vue d'Ensemble](#-vue-densemble)
- [âœ¨ FonctionnalitÃ©s ClÃ©s](#-fonctionnalitÃ©s-clÃ©s)
- [ğŸ—ï¸ Architecture](#-architecture)
- [ğŸ“Š Diagrammes](#-diagrammes)
- [ğŸ§° Stack Technologique](#-stack-technologique)
- [ğŸš€ DÃ©marrage Rapide](#-dÃ©marrage-rapide)
- [ğŸ“ Structure du Projet](#-structure-du-projet)
- [ğŸ”¬ Algorithmes Scientifiques](#-algorithmes-scientifiques)
- [ğŸ›¡ï¸ Gouvernance des DonnÃ©es](#-gouvernance-des-donnÃ©es)
- [ğŸ¤– Intelligence Artificielle](#-intelligence-artificielle)
- [ğŸŒ¿ Agri-Copilot Pro](#-agri-copilot-pro)
- [ğŸŒ Sources de DonnÃ©es Externes](#-sources-de-donnÃ©es-externes)
- [ğŸ“ˆ MÃ©triques de Performance](#-mÃ©triques-de-performance)
- [ğŸ—ºï¸ Roadmap](#-roadmap)
- [ğŸ¤ Contribution](#-contribution)
- [ğŸ“œ Licence](#-licence)

---

## ğŸŒ Vue d'Ensemble

<div align="center">
<img src="images/verticalfarming.PNG" alt="Vertical Farming" width="700"/>
</div>

<br/>

**VertiFlow** est une plateforme de Data Engineering enterprise conÃ§ue pour l'**automatisation intelligente de l'agriculture verticale**. Elle traite **des millions de lectures IoT**, valide les donnÃ©es avec des protocoles **Zero-Trust**, stocke efficacement les sÃ©ries temporelles, et pilote le **contrÃ´le climatique autonome** grÃ¢ce au Machine Learning.

ConÃ§ue pour les **chercheurs agricoles**, les **data engineers** et les **entreprises AgTech**, VertiFlow dÃ©montre comment les pipelines de donnÃ©es industriels peuvent transformer l'agriculture traditionnelle en culture de prÃ©cision pilotÃ©e par les donnÃ©es.

### ğŸ¯ Pourquoi VertiFlow ?

On s'est posÃ© une question simple : pourquoi les fermes verticales perdent-elles encore des donnÃ©es, font-elles confiance aveugle aux capteurs, et n'exploitent pas vraiment le cloud ?

| Ce qu'on fait diffÃ©remment | L'approche classique | Notre solution |
|----------------------------|----------------------|----------------|
| **Validation des donnÃ©es** | On fait confiance aux capteurs | On valide tout avant de stocker |
| **Stockage** | Une seule base | Hybride local + cloud GCP |
| **Machine Learning** | AjoutÃ© aprÃ¨s coup | IntÃ©grÃ© dÃ¨s le dÃ©part |
| **TraÃ§abilitÃ©** | Documentation manuelle | MÃ©tadonnÃ©es automatiques |
| **Quand Ã§a plante** | On perd des donnÃ©es | 3 niveaux de fallback, rien ne se perd |
| **Pour interroger les donnÃ©es** | Il faut Ãªtre dev | On pose des questions en franÃ§ais |

---

## âœ¨ FonctionnalitÃ©s ClÃ©s

### ğŸ“¡ Ingestion temps rÃ©el
Les capteurs envoient leurs mesures toutes les 30 secondes via MQTT. NiFi les rÃ©cupÃ¨re, les valide, les enrichit avec des mÃ©tadonnÃ©es, et les pousse dans Kafka. De lÃ , les donnÃ©es partent vers ClickHouse (local) et BigQuery (cloud).

- Pipeline : **MQTT â†’ NiFi â†’ Kafka â†’ ClickHouse + GCS + BigQuery**
- DÃ©bit : **69 120 messages/jour** par installation
- Latence : **moins de 5 secondes** de bout en bout

### ğŸ›¡ï¸ On ne perd rien
- **Dead Letter Queue (DLQ)** : si quelque chose Ã©choue, on a 3 plans de secours
- **Validation stricte** : une donnÃ©e mal formÃ©e ne rentre jamais dans le systÃ¨me
- **MÃ©tadonnÃ©es automatiques** : on sait d'oÃ¹ vient chaque donnÃ©e, quand, comment
- RÃ©sultat : **99.98% des donnÃ©es arrivent Ã  destination**, mÃªme en cas de panne

### ğŸ’¾ Stockage Hybride : Local + Cloud GCP

**En local (pour la rapiditÃ©) :**
- **ClickHouse** : les sÃ©ries temporelles des capteurs, compression 5:1
- **MongoDB** : les recettes, configurations, logs d'audit

**Sur Google Cloud (pour la puissance) :**
- **GCS (Cloud Storage)** : Data Lake - on archive tout en Parquet/JSON
- **BigQuery** : Analytics lourdes et features pour le ML
- **Vertex AI** : entraÃ®nement des modÃ¨les
- **Looker Studio** : dashboards business

Les donnÃ©es brutes restent 30 jours, les agrÃ©gats 90 jours. Les requÃªtes BI rÃ©pondent en moins d'une seconde.

### ğŸ§  L'intelligence derriÃ¨re tout Ã§a
- **Cortex** : le cerveau qui optimise les recettes de culture en continu
- **Oracle** : prÃ©dit le rendement Ã  J+30 avec 87% de prÃ©cision
- **Classifier** : note la qualitÃ© (Premium, Standard ou Ã  rejeter)
- **Simulateur** : modÃ¨les bio-physiques (VPD, photosynthÃ¨se, transpiration)
- Et pour la lumiÃ¨re, on ajuste dynamiquement le spectre LED (Bleu/Rouge/Far-Red)

### ğŸŒ¿ Agri-Copilot Pro : posez vos questions en franÃ§ais
PlutÃ´t que d'Ã©crire du SQL, demandez simplement :
> "Quelle Ã©tait la tempÃ©rature moyenne de la zone A hier ?"

- Fonctionne en franÃ§ais, anglais, arabe et tamazight
- Utilise **Google Gemini** pour comprendre et gÃ©nÃ©rer les requÃªtes
- Interroge directement ClickHouse et BigQuery
- AccÃ¨s contrÃ´lÃ© selon votre rÃ´le (admin, agronome, agriculteur)

---

## ğŸ—ï¸ Architecture

### Comment Ã§a marche (7 couches)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          VERTIFLOW - HYBRID CLOUD                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  COUCHE 1: LES CAPTEURS                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ ESP32 â†’ MQTT Mosquitto â†’ Edge Gateway                                  â”‚ â”‚
â”‚  â”‚ TempÃ©rature, HumiditÃ©, CO2, PAR, pH, EC, Vision IA                     â”‚ â”‚
â”‚  â”‚ + APIs externes : NASA POWER, Open-Meteo, OpenAQ                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â†“                                               â”‚
â”‚  COUCHE 2: NETTOYAGE (Apache NiFi - 50 processeurs)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â€¢ On valide chaque message (JSON Schema)                               â”‚ â”‚
â”‚  â”‚ â€¢ On ajoute les mÃ©tadonnÃ©es (timestamp, source, version)               â”‚ â”‚
â”‚  â”‚ â€¢ On calcule le VPD Ã  la volÃ©e                                         â”‚ â”‚
â”‚  â”‚ â€¢ Si Ã§a plante â†’ Dead Letter Queue (on ne perd rien)                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â†“                                               â”‚
â”‚  COUCHE 3: TRANSPORT (Apache Kafka)                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Topics: basil_telemetry_full | feedback | external_data | ml_predictionsâ”‚ â”‚
â”‚  â”‚ RÃ©tention 7 jours | Compression Snappy | 12 partitions                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â†“                                               â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚       â†“                                              â†“                       â”‚
â”‚  COUCHE 4: STOCKAGE HYBRIDE                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   ğŸ  LOCAL              â”‚    â”‚   â˜ï¸ GOOGLE CLOUD PLATFORM             â”‚ â”‚
â”‚  â”‚                         â”‚    â”‚                                        â”‚ â”‚
â”‚  â”‚  ğŸ“ˆ ClickHouse          â”‚    â”‚  ğŸ—„ï¸ GCS (Data Lake)                   â”‚ â”‚
â”‚  â”‚   â†’ SÃ©ries temporelles  â”‚    â”‚   â†’ Archive Parquet/JSON              â”‚ â”‚
â”‚  â”‚   â†’ 157 colonnes        â”‚    â”‚                                        â”‚ â”‚
â”‚  â”‚                         â”‚    â”‚  ğŸ“Š BigQuery                           â”‚ â”‚
â”‚  â”‚  ğŸ“ MongoDB             â”‚    â”‚   â†’ Analytics lourdes                  â”‚ â”‚
â”‚  â”‚   â†’ Recettes, configs   â”‚    â”‚   â†’ Features ML                        â”‚ â”‚
â”‚  â”‚   â†’ Audit, live_state   â”‚    â”‚                                        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â†“                                               â”‚
â”‚  COUCHE 5: INTELLIGENCE (Python + GCP)                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ LOCAL:                          â”‚  CLOUD:                              â”‚ â”‚
â”‚  â”‚ â€¢ Cortex (optimisation)         â”‚  â€¢ Vertex AI (entraÃ®nement)         â”‚ â”‚
â”‚  â”‚ â€¢ Oracle (prÃ©diction rendement) â”‚  â€¢ Gemini (NLâ†’SQL)                  â”‚ â”‚
â”‚  â”‚ â€¢ Classifier (qualitÃ©)          â”‚                                      â”‚ â”‚
â”‚  â”‚ â€¢ Simulator (bio-physique)      â”‚                                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â†“                                               â”‚
â”‚  COUCHE 6: BOUCLE DE RÃ‰TROACTION                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Quand le systÃ¨me dÃ©tecte une anomalie (Z-Score), il gÃ©nÃ¨re une         â”‚ â”‚
â”‚  â”‚ commande corrective et l'envoie aux actionneurs via MQTT.              â”‚ â”‚
â”‚  â”‚ â†’ Ajustement HVAC, dosage nutriments, spectre LED, irrigation          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â†“                                               â”‚
â”‚  COUCHE 7: VISUALISATION                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Grafana (ClickHouse) | Looker Studio (BigQuery) | Agri-Copilot Pro     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Le flux des donnÃ©es

```mermaid
graph LR
    A[ğŸŒ¡ï¸ Capteur] -->|MQTT| B[ğŸ“¡ Mosquitto]
    B --> C[âš™ï¸ NiFi]
    C --> D{Valide ?}
    D -->|Oui| E[ğŸ“¬ Kafka]
    D -->|Non| F[âš ï¸ DLQ]
    E --> G[ğŸ“ˆ ClickHouse]
    E --> H[ğŸ—„ï¸ GCS]
    H --> I[ğŸ“Š BigQuery]
    G --> J[ğŸ“ˆ Grafana]
    I --> K[ğŸ“Š Looker]
    I --> L[ğŸŒ¿ Agri-Copilot]
```

---

## ğŸ“Š Diagrammes

Les diagrammes dÃ©taillÃ©s de l'architecture sont disponibles dans le dossier **[docs/diagrams/](docs/diagrams/)** :

| Diagramme | Description | Fichier |
|-----------|-------------|---------|
| ğŸ—ï¸ **Architecture Globale** | Vue d'ensemble des 7 couches | [architecture_globale.mmd](docs/diagrams/architecture_globale.mmd) |
| ğŸ”„ **Pipeline NiFi v5** | 50 processeurs dÃ©taillÃ©s | [data_pipeline_v5.mmd](docs/diagrams/data_pipeline_v5.mmd) |
| ğŸ§® **Algorithmes** | ChaÃ®ne des 11 algorithmes | [algorithmes.mmd](docs/diagrams/algorithmes.mmd) |
| ğŸ“¬ **Kafka** | Architecture de streaming | [kafka.mmd](docs/diagrams/kafka.mmd) |
| âš™ï¸ **NiFi** | Processeurs dÃ©taillÃ©s | [nifi.mmd](docs/diagrams/nifi.mmd) |
| ğŸ“‹ **Master v4** | Vue intÃ©grÃ©e complÃ¨te | [master_v4.mmd](docs/diagrams/master_v4.mmd) |

### Architecture Globale SimplifiÃ©e

```mermaid
flowchart TB
 subgraph SOURCES["ğŸ“¡ Sources - 153 Colonnes"]
        IOT["ğŸŒ¡ï¸ Capteurs IoT"]
        CAMERAS["ğŸ“· Vision IA"]
        APIS["ğŸŒ APIs NASA/MÃ©tÃ©o"]
  end
 subgraph NIFI["âš™ï¸ Apache NiFi"]
        N["Normalisation & Validation"]
  end
 subgraph KAFKA["ğŸ“¬ Apache Kafka"]
        K["Topic Telemetry Full"]
  end
 subgraph DB["ğŸ’¾ Bases de DonnÃ©es"]
        M[("ğŸŸ¢ MongoDB<br/>Temps RÃ©el")]
        C[("ğŸŸ¡ ClickHouse<br/>Historique")]
  end
 subgraph VIZ["ğŸ“Š Visualisation"]
        P["Power BI / Grafana"]
        COPILOT["ğŸŒ¿ Agri-Copilot Pro"]
  end
    IOT ==> N
    CAMERAS --> N
    APIS ==> N
    N -- JSON StandardisÃ© --> K
    K -- Stream Temps RÃ©el --> M
    K -- Batch Insert --> C
    M -- DirectQuery --> P
    C -- DirectQuery --> P
    C -- SQL Analytics --> COPILOT
    M == Alerte ==> N
```

### ChaÃ®ne des Algorithmes Scientifiques

```mermaid
graph TD
    subgraph P1["ğŸ”§ PHASE 1: PRÃ‰-TRAITEMENT<br/>(NiFi)"]
        DATA["ğŸ“¥ DonnÃ©e Brute"] --> A1["A1: Normalisation JSON"]
        A1 --> A2["A2: DÃ©tection Aberration<br/>(Z-Score)"]
        A2 --> A3["A3: Enrichissement<br/>Contextuel"]
    end
    
    subgraph P2["âš¡ PHASE 2: CONTRÃ”LE RÃ‰FLEXE<br/>(MongoDB)"]
        A3 --> A4["A4: Seuillage<br/>Dynamique"]
        A4 --> A5["A5: RÃ¨gles<br/>MÃ©tier"]
    end
    
    subgraph P3["ğŸ“Š PHASE 3: STATISTIQUES<br/>(ClickHouse)"]
        A3 --> A6["A6: AgrÃ©gation<br/>Temporelle"]
        A6 --> A7["A7: CorrÃ©lation<br/>Pearson"]
        A7 --> A8["A8: Segmentation<br/>ANOVA"]
    end
    
    subgraph P4["ğŸ§  PHASE 4: ML & OPTIMISATION<br/>(Python)"]
        A6 --> A9["A9: LSTM<br/>SÃ©ries Temp."]
        A7 --> A9
        A9 --> A10["A10: RandomForest<br/>Classification"]
        A10 --> A11["A11: Gradient Descent<br/>Optimisation"]
    end
    
    A11 -.->|ğŸ”„ Mise Ã  jour Cibles| A4

    style P1 fill:#e3f2fd,stroke:#1565c0
    style P2 fill:#ffebee,stroke:#c62828
    style P3 fill:#fff3e0,stroke:#ef6c00
    style P4 fill:#f3e5f5,stroke:#7b1fa2
```

---

## ğŸ§° Stack Technologique

### Infrastructure locale

| Composant | Technologie | Version | RÃ´le |
|-----------|-------------|---------|------|
| **Capteurs** | ESP32 + MQTT | - | Acquisition des mesures |
| **Broker MQTT** | Eclipse Mosquitto | 2.0+ | QoS 1, topics vertiflow/# |
| **ETL** | Apache NiFi | 1.23+ | 50 processeurs, validation, enrichissement |
| **Streaming** | Apache Kafka | 7.5+ | Bus Ã©vÃ©nementiel, 12 partitions |
| **Time-Series** | ClickHouse | 23.8+ | OLAP, compression Gorilla |
| **Documents** | MongoDB | 7.0+ | Recettes, configs, audit |
| **ML local** | Python + scikit-learn | 3.11+ | Oracle, Classifier, Cortex |
| **Containers** | Docker Compose | 2.20+ | Orchestration locale |
| **Monitoring** | Grafana + Prometheus | - | Dashboards temps rÃ©el |

### Google Cloud Platform

| Service | RÃ´le | IntÃ©gration |
|---------|------|-------------|
| **GCS (Cloud Storage)** | Data Lake - archive brute | NiFi PutGCSObject |
| **BigQuery** | Analytics lourdes, features ML | NiFi PutBigQueryBatch |
| **Vertex AI** | EntraÃ®nement des modÃ¨les | API Python |
| **Gemini** | NLâ†’SQL pour Agri-Copilot | API REST |
| **Looker Studio** | Dashboards business | Connecteur BigQuery |

### Pourquoi ces choix ?

- **NiFi plutÃ´t qu'Airflow** : on a besoin de streaming temps rÃ©el, pas de batch. Et NiFi trace automatiquement d'oÃ¹ vient chaque donnÃ©e.
- **ClickHouse plutÃ´t que TimescaleDB** : 10Ã— plus rapide sur les agrÃ©gations, et il s'intÃ¨gre nativement avec Kafka.
- **Kafka plutÃ´t que RabbitMQ** : on peut rejouer les messages pour rÃ©-entraÃ®ner les modÃ¨les ML. C'est un log, pas une queue.
- **GCP plutÃ´t qu'AWS** : BigQuery est imbattable pour les analytics ad-hoc, et Gemini s'intÃ¨gre bien avec notre assistant IA.

---

## ğŸš€ DÃ©marrage Rapide

### PrÃ©requis

- **Docker** 24.0+ & **Docker Compose** 2.20+
- **Python** 3.11+
- **8 Go RAM** minimum (16 Go recommandÃ©)
- **50 Go** d'espace disque libre

### Installation

```bash
# 1. Cloner le repository
git clone https://github.com/vertiflow-team/vertiflow-data-platform.git
cd vertiflow-data-platform

# 2. Configurer l'environnement
cp .env.example .env
# Ã‰diter .env avec vos paramÃ¨tres (la plupart des valeurs par dÃ©faut fonctionnent)

# 3. DÃ©marrer l'infrastructure (Kafka, ClickHouse, MongoDB, NiFi)
docker-compose up -d

# 4. Attendre les healthchecks (~2 minutes)
docker-compose ps  # Tous les services doivent afficher "healthy"

# 5. CrÃ©er l'environnement virtuel Python
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# 6. Installer les dÃ©pendances
pip install -r requirements.txt

# 7. Initialiser les bases de donnÃ©es
python infrastructure/init_infrastructure.py

# 8. TÃ©lÃ©charger les datasets externes (optionnel mais recommandÃ©)
chmod +x scripts/download_all_sources.sh
./scripts/download_all_sources.sh --priority 1  # 40 MB, ~10 min
```

### VÃ©rifier l'Installation

```bash
# Lancer les tests d'intÃ©gration
pytest tests/integration/ -v

# Tester le pipeline MQTT -> ClickHouse
python tests/integration/test_mqtt_to_clickhouse.py

# VÃ©rifier les donnÃ©es
docker exec -it clickhouse clickhouse-client --query \
  "SELECT count(*) FROM vertiflow.sensor_telemetry"
```

### AccÃ©der aux Interfaces

| Service | URL | Identifiants |
|---------|-----|--------------|
| **NiFi UI** | https://localhost:8443/nifi | admin / admin |
| **Grafana** | http://localhost:3000 | admin / admin |
| **ClickHouse** | localhost:9000 (natif) / localhost:8123 (HTTP) | default / (sans mot de passe) |
| **MongoDB** | localhost:27017 | vertiflow / vertiflow_password |
| **Agri-Copilot Pro** | http://localhost:8501 (Streamlit) | - |

---

## ğŸ“ Structure du Projet

```
vertiflow-data-platform/
â”‚
â”œâ”€â”€ ğŸ¤– agri-copilot-pro/              # ASSISTANT IA INTÃ‰GRÃ‰
â”‚   â”œâ”€â”€ app_pro.py                    # Interface Streamlit
â”‚   â”œâ”€â”€ main.py                       # API FastAPI
â”‚   â””â”€â”€ requirements.txt              # DÃ©pendances spÃ©cifiques
â”‚
â”œâ”€â”€ ğŸ§  cloud_citadel/                 # COUCHE 5-6: INTELLIGENCE
â”‚   â”œâ”€â”€ connectors/
â”‚   â”‚   â”œâ”€â”€ feedback_loop.py          # Pipeline rÃ©-entraÃ®nement
â”‚   â”‚   â””â”€â”€ stream_processor.py       # Processeur Kafka â†’ ClickHouse
â”‚   â””â”€â”€ nervous_system/
â”‚       â”œâ”€â”€ classifier.py             # ALGO A10 - Classification qualitÃ©
â”‚       â”œâ”€â”€ cortex.py                 # ALGO A11 - Optimisation recettes
â”‚       â”œâ”€â”€ oracle.py                 # ALGO A9 - PrÃ©diction rendement
â”‚       â””â”€â”€ simulator.py              # ModÃ¨les bio-physiques
â”‚
â”œâ”€â”€ âš™ï¸ config/                        # CONFIGURATION
â”‚   â”œâ”€â”€ environments/                 # Configs par environnement
â”‚   â”œâ”€â”€ mosquitto/                    # Config MQTT
â”‚   â”œâ”€â”€ agronomic_parameters.yaml     # ParamÃ¨tres agronomiques
â”‚   â””â”€â”€ nifi_pipeline_*.yaml          # Templates NiFi
â”‚
â”œâ”€â”€ ğŸ“Š dashboards/                    # COUCHE 7: VISUALISATION
â”‚   â””â”€â”€ grafana/                      # Dashboards Grafana
â”‚
â”œâ”€â”€ ğŸ“š docs/                          # DOCUMENTATION
â”‚   â”œâ”€â”€ diagrams/                     # ğŸ”¹ Diagrammes Mermaid (.mmd)
â”‚   â”‚   â”œâ”€â”€ architecture_globale.mmd
â”‚   â”‚   â”œâ”€â”€ data_pipeline_v5.mmd
â”‚   â”‚   â”œâ”€â”€ algorithmes.mmd
â”‚   â”‚   â””â”€â”€ master_v4.mmd
â”‚   â”œâ”€â”€ architecture/                 # Docs architecture technique
â”‚   â”œâ”€â”€ schemas/                      # Contrats de donnÃ©es
â”‚   â”‚   â”œâ”€â”€ telemetry_v3.json
â”‚   â”‚   â””â”€â”€ command_v3.json
â”‚   â””â”€â”€ *.md                          # Documentation gÃ©nÃ©rale
â”‚
â”œâ”€â”€ ğŸ—ï¸ infrastructure/               # INFRASTRUCTURE AS CODE
â”‚   â”œâ”€â”€ init_infrastructure.py        # Script setup master
â”‚   â””â”€â”€ init_scripts/
â”‚       â”œâ”€â”€ clickhouse/               # Scripts init ClickHouse
â”‚       â””â”€â”€ mongodb/                  # Scripts init MongoDB
â”‚
â”œâ”€â”€ ğŸ¤– models/                        # MODÃˆLES ML
â”‚   â”œâ”€â”€ train_oracle_model.py         # EntraÃ®nement Oracle
â”‚   â””â”€â”€ train_quality_classifier.py   # EntraÃ®nement Classifier
â”‚
â”œâ”€â”€ ğŸ”§ scripts/                       # SCRIPTS AUTOMATISATION
â”‚   â”œâ”€â”€ simulators/                   # Simulateurs IoT
â”‚   â”‚   â”œâ”€â”€ iot_sensor_simulator.py
â”‚   â”‚   â””â”€â”€ led_spectrum_simulator.py
â”‚   â”œâ”€â”€ etl/                          # Scripts ETL
â”‚   â””â”€â”€ data_sources/                 # Handlers APIs externes
â”‚
â”œâ”€â”€ ğŸ§ª tests/                         # TESTS AUTOMATISÃ‰S
â”‚   â”œâ”€â”€ unit/                         # Tests unitaires
â”‚   â”œâ”€â”€ integration/                  # Tests d'intÃ©gration
â”‚   â””â”€â”€ e2e/                          # Tests bout-en-bout
â”‚
â”œâ”€â”€ ğŸ”’ security/                      # SÃ‰CURITÃ‰ & CERTIFICATS
â”œâ”€â”€ ğŸ“ˆ monitoring/                    # STACK OBSERVABILITÃ‰
â”œâ”€â”€ â˜¸ï¸ k8s/                           # KUBERNETES (futur)
â”œâ”€â”€ ğŸ“¦ mlops/                         # MLFLOW (futur)
â”‚
â”œâ”€â”€ docker-compose.yml                # Services principaux
â”œâ”€â”€ docker-compose.metrics.yml        # Stack monitoring
â”œâ”€â”€ docker-compose.secure.yml         # Configuration sÃ©curisÃ©e
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ Makefile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”¬ Algorithmes Scientifiques

VertiFlow implÃ©mente **11 algorithmes scientifiques** pour le traitement et l'intelligence des donnÃ©es :

| ID | Nom | Type | Localisation | Fonction |
|----|-----|------|--------------|----------|
| A1 | Normalisation JSON | ETL | NiFi | Standardisation formats hÃ©tÃ©rogÃ¨nes |
| A2 | DÃ©tection Aberration Z-Score | Statistique | NiFi | Rejet donnÃ©es capteurs dÃ©fectueux (seuil 3Ïƒ) |
| A3 | Enrichissement Contextuel | Fusion | NiFi | Ajout mÃ©tadonnÃ©es, lineage lÃ©gal |
| A4 | Seuillage Dynamique | Logique | MongoDB | Alertes temps rÃ©el vs cibles expert |
| A5 | Moteur de RÃ¨gles | BoolÃ©en | MongoDB | Actions rÃ©flexe (arrÃªt urgence) |
| A6 | AgrÃ©gation Temporelle | SQL | ClickHouse | Moyennes glissantes, rÃ©duction bruit |
| A7 | CorrÃ©lation Pearson | SQL | ClickHouse | Prouver liens causaux (lumiÃ¨re vs poids) |
| A8 | Segmentation ANOVA | SQL | ClickHouse | Comparaison A/B testing des racks |
| **A9** | **LSTM SÃ©ries Temporelles** | Deep Learning | `oracle.py` | PrÃ©diction date rÃ©colte (horizon 7j) |
| **A10** | **RandomForest Classification** | ML SupervisÃ© | `classifier.py` | PrÃ©diction qualitÃ© (Premium/Standard/Rejet) |
| **A11** | **Gradient Descent Optimisation** | Math | `cortex.py` | Optimisation recette (rendement Ã— qualitÃ© âˆ’ coÃ»t) |

### ModÃ¨les Bio-Physiques (simulator.py)

- **VPD (Vapor Pressure Deficit) :** Formule de Tetens
  ```
  E_s(T) = 0.6108 Ã— exp(17.27T / (T+237.3)) kPa
  ```
- **Taux PhotosynthÃ¨se :** ModÃ¨le Farquhar avec cinÃ©tique CO2 Michaelis-Menten
- **Transpiration :** Ã‰quation Penman-Monteith
- **DLI (Daily Light Integral) :** `DLI = (PPFD Ã— durÃ©e_jour Ã— 3.6) / 10â¶` mol/mÂ²/jour
- **Effets Spectraux :** Impacts Bleu/Rouge/Far-Red sur la morphologie

---

## ğŸ›¡ï¸ Comment on gÃ¨re la qualitÃ© des donnÃ©es

On ne fait pas confiance aux capteurs aveuglÃ©ment. Voici notre approche :

### Tout est validÃ© Ã  l'entrÃ©e

Chaque message MQTT passe par un contrÃ´le strict avant d'aller plus loin. Le schÃ©ma attendu :

```json
{
  "device_id": "ESP32-XXXX",
  "zone": "ZONE_A ou ZONE_B ou NURSERY",
  "metric_type": "temperature, humidity, co2, par, ph, ec",
  "value": "un nombre",
  "timestamp": "format ISO 8601"
}
```

Si le message ne correspond pas â†’ il est rejetÃ© et envoyÃ© dans la Dead Letter Queue.

### On sait d'oÃ¹ viennent les donnÃ©es

Chaque donnÃ©e valide est enrichie automatiquement avec :
- Quand elle a Ã©tÃ© ingÃ©rÃ©e
- Quelle version du schÃ©ma
- Quel environnement (dev/prod)
- Son niveau de qualitÃ© (Bronze/Silver/Gold)
- Sa source d'origine

### Si quelque chose Ã©choue, on ne perd rien

```
Message invalide â†’ On l'enveloppe avec l'erreur
                 â†“
           Topic Kafka (vertiflow.errors)
                 â†“
           Fichier backup (/logs/dlq)
```

Trois niveaux de fallback. On peut toujours revenir voir ce qui s'est passÃ©.

### Niveaux de donnÃ©es (Bronze â†’ Silver â†’ Gold)

| Niveau | C'est quoi | Combien de temps | OÃ¹ |
|--------|------------|------------------|-----|
| **Bronze** | Les donnÃ©es brutes des capteurs | 30 jours | ClickHouse + GCS |
| **Silver** | AgrÃ©gÃ©es par minute et par heure | 90 jours | ClickHouse + BigQuery |
| **Gold** | Features ML, prÃ©dictions | Permanent | ClickHouse + MongoDB + BigQuery |

---

## ğŸ¤– Les cerveaux de VertiFlow

### Oracle : prÃ©dire le rendement

On entraÃ®ne un RandomForest sur les donnÃ©es historiques pour prÃ©dire combien de grammes de basilic on va rÃ©colter dans 30 jours.

**Ce qu'il regarde :**
- TempÃ©rature moyenne sur 24h
- LumiÃ¨re PAR moyenne
- HumiditÃ© relative
- Niveau de CO2
- StabilitÃ© de la tempÃ©rature (Ã©cart-type)

**RÃ©sultats :** erreur de Â±12g, prÃ©cision de 87%. L'infÃ©rence prend moins de 100ms.

### Classifier : noter la qualitÃ©

Il classe chaque lot en trois catÃ©gories : **Premium**, **Standard** ou **Ã€ rejeter**.

Il analyse le VPD, la lumiÃ¨re cumulÃ©e (DLI), la conductivitÃ© de la solution nutritive et l'Ã¢ge des plants.

### Cortex : optimiser les recettes

C'est le cerveau qui ajuste les paramÃ¨tres de culture en continu. Il cherche le meilleur compromis entre rendement, qualitÃ© et coÃ»t Ã©nergÃ©tique.

```
Score = Rendement Ã— 0.6 + QualitÃ© Ã— 0.4 âˆ’ CoÃ»t Ã— 0.2
```

Il respecte des contraintes biologiques :
- TempÃ©rature entre 18 et 28Â°C
- EC entre 1.2 et 2.5 mS/cm
- DLI entre 10 et 20 mol/mÂ²/jour

Cycle d'optimisation : toutes les 24h.

---

## ğŸŒ¿ Agri-Copilot Pro

<div align="center">

[![Streamlit](https://img.shields.io/badge/Streamlit-1.31%2B-FF4B4B)](https://streamlit.io/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109%2B-009485)](https://fastapi.tiangolo.com/)
[![Gemini](https://img.shields.io/badge/Google%20Gemini-AI-4285F4)](https://ai.google.dev/)
[![BigQuery](https://img.shields.io/badge/BigQuery-Analytics-669DF6)](https://cloud.google.com/bigquery)

</div>

Notre assistant IA. Au lieu d'Ã©crire du SQL, vous posez des questions en franÃ§ais (ou en anglais, arabe, tamazight) et il vous rÃ©pond.

**Comment Ã§a marche :**
1. Vous tapez : "Quelle Ã©tait la tempÃ©rature moyenne de la zone A hier ?"
2. Gemini comprend la question et gÃ©nÃ¨re la requÃªte SQL
3. La requÃªte est envoyÃ©e Ã  ClickHouse ou BigQuery
4. Vous recevez la rÃ©ponse avec un graphique

**Ce qu'il peut faire :**

| | |
|---|---|
| ğŸ—£ï¸ Comprendre le franÃ§ais, l'anglais, l'arabe | ğŸ“Š Interroger ClickHouse et BigQuery |
| ğŸ” Limiter l'accÃ¨s selon votre rÃ´le | ğŸ’¾ Mettre en cache les rÃ©ponses frÃ©quentes |
| ğŸ“ˆ GÃ©nÃ©rer des graphiques Plotly | âš¡ Temps de rÃ©ponse < 2 secondes |

### Pour l'essayer

```bash
cd agri-copilot-pro
pip install -r requirements.txt

# Interface chat
streamlit run app_pro.py
# â†’ http://localhost:8501

# API REST
uvicorn main:app --host 0.0.0.0 --port 8000
# â†’ http://localhost:8000/api/docs
```

### Exemples de questions

```
"Compare l'humiditÃ© entre les zones A et B sur les 7 derniers jours"
"Quel Ã©tait le pic de CO2 hier dans la nursery ?"
"Show me the correlation between temperature and yield"
"Ø£Ø¸Ù‡Ø± Ù„ÙŠ Ù…ØªÙˆØ³Ø· Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø©"
```

> ğŸ“– Plus de dÃ©tails dans [agri-copilot-pro/README.md](agri-copilot-pro/README.md)

---

## ğŸŒ Sources de DonnÃ©es Externes

### Datasets IntÃ©grÃ©s

| Source | Description | Volume | Usage |
|--------|-------------|--------|-------|
| **Cooper Hewitt PFC** | MIT OpenAg 73k datapoints environnementaux | 12 MB | Validation benchmark |
| **Basil Viability FS2** | ExpÃ©rience croissance basilic MIT (2018-2019) | 23 MB | Calibration modÃ¨les |
| **NASA POWER** | Irradiance solaire & climat (Casablanca) | 2.5 MB | Features ML (saisonnalitÃ©) |
| **OpenAg Recipes** | Recettes de culture validÃ©es | 5 MB | Templates config contrÃ´le |
| **Wageningen Research** | Ã‰tudes spectre LED | 250 MB | Optimisation spectrale |

### TÃ©lÃ©chargement DonnÃ©es Externes

```bash
# PrioritÃ© 1 : Quick wins (40 MB, 10 min)
./scripts/download_all_sources.sh --priority 1

# PrioritÃ© 2 : AcadÃ©mique + MÃ©tÃ©o (650 MB, 30 min)
./scripts/download_all_sources.sh --priority 2

# Toutes les sources (1.1 GB, 1-2 heures)
./scripts/download_all_sources.sh --priority all
```

---

## ğŸ“ˆ MÃ©triques de Performance

### CapacitÃ©s TestÃ©es

| MÃ©trique | Valeur | Notes |
|----------|--------|-------|
| **Throughput** | 2 880 msg/min | 8 capteurs Ã— 3 zones Ã— 2 msg/min Ã— 60s |
| **Latence (P99)** | < 5 secondes | MQTT â†’ ClickHouse bout-en-bout |
| **Compression** | Ratio 5:1 | Codec Gorilla sur floats |
| **Vitesse RequÃªte** | < 500ms | SELECT sur 30 jours (10M lignes) |
| **Stockage (30j)** | ~2 GB | Avec rotation & compression |
| **SuccÃ¨s DLQ** | 99.98% | 0.02% perte (Ã©chec total Kafka) |

### ScalabilitÃ©

```
Installation Unique (3 Zones):
  - TÃ©lÃ©mÃ©trie: 33 MB/mois (compressÃ©)
  - Images: 370 MB/mois (optimisÃ©)
  - Logs: 315 MB/mois (rotation 30j)

10 Installations:
  - Total: ~20 GB/mois (stable avec TTL)
  - Cluster ClickHouse recommandÃ©
```

---

## ğŸ“Š Ã‰tat Actuel

### âœ… Fonctionnel

- Infrastructure Docker Compose (7 services)
- Health checks pour tous les services
- Module Simulateur (modÃ¨les bio-physiques complets)
- SchÃ©mas bases de donnÃ©es (ClickHouse + MongoDB)
- Suite de tests (16+ fichiers avec fixtures)
- Documentation complÃ¨te d'architecture
- Assistant IA Agri-Copilot Pro

### ğŸ”„ En Cours

- ModÃ¨les ML (framework prÃªt, besoin donnÃ©es rÃ©elles d'entraÃ®nement)
- Traitement Stream (design complet, intÃ©gration en cours)
- Boucle de Feedback (conÃ§ue mais non opÃ©rationnelle)
- Pipelines NiFi (templates existants, dÃ©ploiement partiel)

### ğŸ“‹ PlanifiÃ©

- DÃ©ploiement Kubernetes
- Endpoints REST API
- Dashboard web React
- Vision par ordinateur pour dÃ©tection maladies

---

## ğŸ—ºï¸ Roadmap

### v1.0 (Actuel) - Plateforme Core

- [x] Ingestion tÃ©lÃ©mÃ©trie temps rÃ©el (MQTT â†’ Kafka â†’ ClickHouse)
- [x] Validation Zero-Trust + DLQ 3 niveaux
- [x] Stockage hybride (ClickHouse + MongoDB)
- [x] ContrÃ´le autonome Cortex (framework)
- [x] PrÃ©dictions ML Oracle (framework)
- [x] IntÃ©gration donnÃ©es externes (NASA, OpenAg)
- [x] Suite de tests complÃ¨te
- [x] Assistant IA Agri-Copilot Pro
- [ ] Hardening dÃ©ploiement production

### v1.1 (Q2 2026) - ObservabilitÃ©++ âœ…

- [x] Sidecar Metrics Collector (Prometheus)
- [x] Framework Shadow Validation (Great Expectations)
- [x] Data Catalog Live (auto-gÃ©nÃ©rÃ©)
- [x] Dashboards Grafana amÃ©liorÃ©s
- [x] Endpoints REST API

### v1.2 (Q3 2026) - Computer Vision

- [ ] IntÃ©gration PlantCV (analyse d'image)
- [ ] DÃ©tection automatique maladies
- [ ] Mesure plant_height sans capteur

### v2.0 (Q4 2026) - Multi-Tenant & Scale-Out

- [ ] Support multi-installation (1 â†’ N fermes)
- [ ] Cluster ClickHouse (rÃ©plication)
- [ ] Cluster Kafka (3+ brokers)
- [ ] API GraphQL
- [ ] Dashboard web (React)
- [ ] DÃ©ploiement Kubernetes

---

## ğŸ¤ Contribution

Nous accueillons les contributions ! Veuillez lire notre [CONTRIBUTING.md](CONTRIBUTING.md) pour :

- Directives de rapport de bugs
- Processus de demande de fonctionnalitÃ©s
- Exigences pour les pull requests
- Standards de code (PEP 8, type hints)

### Configuration DÃ©veloppement

```bash
# Cloner le repo
git clone https://github.com/vertiflow-team/vertiflow-data-platform.git
cd vertiflow-data-platform

# CrÃ©er environnement virtuel
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# Installer dÃ©pendances
pip install -r requirements.txt

# Lancer les tests
pytest tests/ -v

# Formatage code
black cloud_citadel/ scripts/
flake8 cloud_citadel/ scripts/
```

### Convention de Commits

Nous utilisons [Conventional Commits](https://www.conventionalcommits.org/) :

```
feat: Ajouter support authentification MQTT
fix: Corriger calcul VPD dans simulator
docs: Mettre Ã  jour diagrammes architecture
refactor: Simplifier logique dÃ©cision Cortex
test: Ajouter tests intÃ©gration pour DLQ
```

---

## ğŸ“œ Licence

Ce projet est sous licence **GNU General Public License v3.0** (GPL-3.0).
Voir [LICENSE](LICENSE) pour le texte complet.

**En rÃ©sumÃ© :**
- Usage commercial autorisÃ©
- Modifications autorisÃ©es
- Distribution autorisÃ©e
- Obligation de divulguer le source (copyleft)
- Les dÃ©rivÃ©s doivent utiliser la mÃªme licence

---

## ğŸ“ Contact & Support

- **Issues :** [GitHub Issues](https://github.com/vertiflow-team/vertiflow-data-platform/issues)
- **Discussions :** [GitHub Discussions](https://github.com/vertiflow-team/vertiflow-data-platform/discussions)
- **Documentation :** [docs/](docs/)

---

## ğŸ“š Citation

Si vous utilisez VertiFlow dans vos recherches, veuillez citer :

```bibtex
@software{vertiflow2025,
  title = {VertiFlow: Plateforme Data Industrielle pour l'Agriculture Verticale Intelligente},
  author = {Mounir and Imrane and Mouhammed and Asama and Zakaria},
  year = {2025},
  url = {https://github.com/vertiflow-team/vertiflow-data-platform},
  license = {GPL-3.0}
}
```

---

## ğŸ™ Remerciements

Ce projet s'appuie sur d'excellents travaux de :

- **MIT OpenAg Initiative** - Datasets Cooper Hewitt & Basil FS2
- **Wageningen University** - Recherche horticulture LED
- **NASA POWER Project** - DonnÃ©es climatiques ouvertes
- **Apache Software Foundation** - NiFi, Kafka
- **ClickHouse Inc.** - Base de donnÃ©es OLAP
- **MongoDB Inc.** - Base de donnÃ©es NoSQL

---

<div align="center">

<br/>

## ğŸ« Cadre de Formation

<br/>

**Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre du programme national JobInTech**

<img src="images/vue1.jpg" alt="VertiFlow System" width="600"/>

<br/><br/>

| | |
|:---:|:---|
| **Programme** | JobInTech |
| **MinistÃ¨re** | Transition NumÃ©rique et RÃ©forme de l'Administration (MTNRA) |
| **Partenaire** | Groupe CDG |
| **OpÃ©rateur** | Maroc Numeric Cluster (MNC) |
| **Formation** | Data Engineering |
| **Ã‰cole** | YNOV Maroc Campus |

<br/>

---

**Construit avec soin pour une agriculture durable** ğŸŒ±

<br/>

[â¬†ï¸ Retour en haut](#-vertiflow)

<br/>

---

**Â© 2025 Ã‰quipe DATAFLOW - Tous droits rÃ©servÃ©s**

*Projet de Fin de Formation Data Engineering - JobInTech / YNOV Maroc Campus*

</div>
