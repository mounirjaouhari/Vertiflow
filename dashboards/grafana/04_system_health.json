/*
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘               VERTIFLOW - SYSTEM HEALTH & INFRASTRUCTURE DASHBOARD            â•‘
â•‘          Real-time Monitoring: Compute, Storage, Services, Alerts             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DOCUMENT METADATA                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Reference: TICKET-122                                                        â”‚
â”‚ Date: January 3, 2026                                                        â”‚
â”‚ Version: 1.0.0                                                               â”‚
â”‚ Author/Team: @Imrane (DevOps Lead), @Mouhammed (Platform Engineer)          â”‚
â”‚ Classification: Technical - Internal                                         â”‚
â”‚ Status: Production                                                           â”‚
â”‚ Last Modified: 2026-01-03                                                    â”‚
â”‚                                                                              â”‚
â”‚ PURPOSE:                                                                     â”‚
â”‚ This dashboard provides comprehensive infrastructure health monitoring       â”‚
â”‚ for operations and DevOps teams. It enables:                                â”‚
â”‚                                                                              â”‚
â”‚ - Real-time system resource monitoring (CPU, memory, disk, network)         â”‚
â”‚ - Container and service health tracking (Docker, Kubernetes)                â”‚
â”‚ - Data pipeline status (Kafka, ClickHouse, MongoDB, Redis)                  â”‚
â”‚ - API and application performance metrics                                   â”‚
â”‚ - Alert management and incident response                                    â”‚
â”‚ - Capacity planning and trend analysis                                      â”‚
â”‚                                                                              â”‚
â”‚ KEY INFRASTRUCTURE COMPONENTS MONITORED:                                     â”‚
â”‚ 1. Compute Resources                                                         â”‚
â”‚    - CPU utilization: Host and per-container                                â”‚
â”‚    - Memory usage: Host RAM, swap, per-service                              â”‚
â”‚    - Disk I/O: Read/write throughput, latency                               â”‚
â”‚    - Network: Bandwidth in/out, packet loss, latency                        â”‚
â”‚                                                                              â”‚
â”‚ 2. Data Infrastructure                                                       â”‚
â”‚    - Kafka: Broker health, lag, throughput (events/sec)                      â”‚
â”‚    - ClickHouse: Query performance, storage usage, replication               â”‚
â”‚    - MongoDB: Connection pool, oplog size, index usage                       â”‚
â”‚    - Redis: Memory usage, eviction rate, commands/sec                        â”‚
â”‚                                                                              â”‚
â”‚ 3. Container Orchestration                                                   â”‚
â”‚    - Docker: Container count, running/stopped, resource limits               â”‚
â”‚    - Kubernetes: Pod status, node health, resource requests vs actual        â”‚
â”‚    - Volume mounts: Disk usage per container                                 â”‚
â”‚                                                                              â”‚
â”‚ 4. Application Services                                                      â”‚
â”‚    - NiFi: Processor uptime, data flow rate, queued records                  â”‚
â”‚    - Grafana: Dashboard loads, user sessions                                 â”‚
â”‚    - Prometheus: Scrape success rate, sample rate                            â”‚
â”‚    - API endpoints: Response time, error rate, throughput                    â”‚
â”‚                                                                              â”‚
â”‚ DESIGNED FOR:                                                                â”‚
â”‚ - DevOps Lead: Infrastructure health, capacity planning, incident response  â”‚
â”‚ - Platform Engineer: Performance tuning, bottleneck identification           â”‚
â”‚ - SRE Team: Reliability metrics, uptime tracking, scaling decisions          â”‚
â”‚ - On-call Engineer: Real-time alerts, quick incident diagnosis               â”‚
â”‚                                                                              â”‚
â”‚ ASSIGNED TO: @Imrane (DevOps Lead)                                          â”‚
â”‚ TEAM: @Imrane (infrastructure), @Mouhammed (platform), @Mounir (oversight)  â”‚
â”‚ TICKET: TICKET-122                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
*/

{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": "-- Grafana --",
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  },
  "editable": false,
  "gnetId": null,
  "graphTooltip": 1,
  "id": null,
  "links": [
    {
      "asDropdown": false,
      "icon": "dashboard",
      "includeVars": false,
      "keepTime": true,
      "tags": ["vertiflow", "operational"],
      "targetBlank": true,
      "title": "Operational Cockpit",
      "tooltip": "Real-time operations monitoring",
      "type": "dashboards",
      "url": "/d/operational-cockpit"
    },
    {
      "asDropdown": false,
      "icon": "doc",
      "includeVars": false,
      "keepTime": true,
      "tags": ["vertiflow", "finance"],
      "targetBlank": true,
      "title": "Executive Finance",
      "tooltip": "Business metrics and profitability",
      "type": "dashboards",
      "url": "/d/executive-finance"
    }
  ],
  "panels": [
    /*
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘ PANEL 1: INFRASTRUCTURE STATUS CARDS (Top Row)                   â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘ Purpose: Quick health check of all critical components           â•‘
    â•‘ Data Source: Prometheus.up{job=~".*"}                            â•‘
    â•‘ Update Interval: Real-time (30-second scrape)                   â•‘
    â•‘ Visualization: Stat cards (color-coded up/down status)           â•‘
    â•‘                                                                   â•‘
    â•‘ Components Monitored:                                             â•‘
    â•‘ 1. Kafka Cluster                                                  â•‘
    â•‘    - Status: UP (green) or DOWN (red)                            â•‘
    â•‘    - Brokers: Count of active broker nodes                       â•‘
    â•‘    - Topics: Number of monitored topics                          â•‘
    â•‘    - Why: If Kafka down, all data pipelines stall                â•‘
    â•‘                                                                   â•‘
    â•‘ 2. ClickHouse Server                                              â•‘
    â•‘    - Status: UP (green) or DOWN (red)                            â•‘
    â•‘    - QPS: Queries per second (target >100 for analytics)         â•‘
    â•‘    - Replicas: Count of healthy replica servers                  â•‘
    â•‘    - Why: OLAP database for all analytics; downtime = no reports â•‘
    â•‘                                                                   â•‘
    â•‘ 3. MongoDB Replica Set                                            â•‘
    â•‘    - Status: Primary UP, Secondaries UP/DOWN                     â•‘
    â•‘    - Connections: Active client connections                      â•‘
    â•‘    - Oplog lag: How far behind replicas are (should be <1s)      â•‘
    â•‘    - Why: Document store for optimization runs, metadata         â•‘
    â•‘                                                                   â•‘
    â•‘ 4. Redis Cache                                                    â•‘
    â•‘    - Status: UP (green) or DOWN (red)                            â•‘
    â•‘    - Memory used: % of configured max                            â•‘
    â•‘    - Commands/sec: Cache hit rate indicator                      â•‘
    â•‘    - Why: In-memory cache; if down, lookups slow                 â•‘
    â•‘                                                                   â•‘
    â•‘ 5. Prometheus Server                                              â•‘
    â•‘    - Status: UP (green) or DOWN (red)                            â•‘
    â•‘    - Scrape rate: % targets successfully scraped                 â•‘
    â•‘    - Storage: TSDB disk usage                                    â•‘
    â•‘    - Why: Metrics collection; if down, can't monitor anything    â•‘
    â•‘                                                                   â•‘
    â•‘ 6. Grafana Server                                                 â•‘
    â•‘    - Status: UP (green) or DOWN (red)                            â•‘
    â•‘    - Users online: Active dashboard users                        â•‘
    â•‘    - Request latency: Dashboard load time (should be <200ms)      â•‘
    â•‘    - Why: Visualization platform; users can't view dashboards    â•‘
    â•‘                                                                   â•‘
    â•‘ Why: DevOps lead needs instant view of infrastructure health.    â•‘
    â•‘      Red status = incident. Green = all systems operational.     â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    */
    {
      "datasource": "Prometheus",
      "description": "Quick health check: Critical infrastructure components",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [
            {
              "options": {
                "0": {
                  "color": "red",
                  "text": "DOWN"
                },
                "1": {
                  "color": "green",
                  "text": "UP"
                }
              },
              "type": "value"
            }
          ],
          "max": 1,
          "min": 0,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "red",
                "value": null
              },
              {
                "color": "green",
                "value": 1
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 6,
        "w": 24,
        "x": 0,
        "y": 0
      },
      "id": 1,
      "options": {
        "graphMode": "area",
        "justifyMode": "center",
        "orientation": "auto",
        "reduceOptions": {
          "values": false,
          "fields": "",
          "calcs": [
            "lastNotNull"
          ]
        },
        "text": {},
        "textMode": "auto"
      },
      "pluginVersion": "8.0.0",
      "targets": [
        {
          "expr": "up{job=\"kafka\"} OR on() vector(0)",
          "legendFormat": "Kafka",
          "refId": "A"
        },
        {
          "expr": "up{job=\"clickhouse\"} OR on() vector(0)",
          "legendFormat": "ClickHouse",
          "refId": "B"
        },
        {
          "expr": "up{job=\"mongodb\"} OR on() vector(0)",
          "legendFormat": "MongoDB",
          "refId": "C"
        },
        {
          "expr": "up{job=\"redis\"} OR on() vector(0)",
          "legendFormat": "Redis",
          "refId": "D"
        },
        {
          "expr": "up{job=\"prometheus\"} OR on() vector(0)",
          "legendFormat": "Prometheus",
          "refId": "E"
        },
        {
          "expr": "up{job=\"grafana\"} OR on() vector(0)",
          "legendFormat": "Grafana",
          "refId": "F"
        }
      ],
      "title": "ğŸš¨ INFRASTRUCTURE STATUS",
      "type": "stat"
    },

    /*
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘ PANEL 2: CPU & MEMORY UTILIZATION (Host Level)                   â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘ Purpose: Track compute resource usage across infrastructure       â•‘
    â•‘ Data Source: Prometheus (node-exporter metrics)                  â•‘
    â•‘ Update Interval: Real-time (15-second intervals)                 â•‘
    â•‘ Visualization: Dual-axis line chart with thresholds              â•‘
    â•‘                                                                   â•‘
    â•‘ Metrics:                                                          â•‘
    â•‘ 1. CPU Utilization %                                              â•‘
    â•‘    - Formula: (1 - idle_time) Ã— 100                               â•‘
    â•‘    - Yellow threshold: >70% (approaching saturation)              â•‘
    â•‘    - Red threshold: >90% (at saturation)                          â•‘
    â•‘    - Why: If sustained >85%, may need to scale vertically         â•‘
    â•‘                                                                   â•‘
    â•‘ 2. Memory Utilization %                                           â•‘
    â•‘    - Formula: (used_bytes / total_bytes) Ã— 100                    â•‘
    â•‘    - Yellow threshold: >80% (memory pressure)                     â•‘
    â•‘    - Red threshold: >95% (critical, may trigger OOM killer)       â•‘
    â•‘    - Why: Linux will kill processes if memory exhausted           â•‘
    â•‘                                                                   â•‘
    â•‘ Per-Host Breakdown:                                               â•‘
    â•‘ - api-server-1, api-server-2: Should be similar load              â•‘
    â•‘ - data-warehouse-1: Higher memory (ClickHouse)                    â•‘
    â•‘ - kafka-broker-1,2,3: Balanced load (cluster)                     â•‘
    â•‘ - gpu-node-1 (optional): GPU compute for ML inference              â•‘
    â•‘                                                                   â•‘
    â•‘ Why: Operators need to know when to add resources:                â•‘
    â•‘      - High CPU: Can add CPU cores or distribute load             â•‘
    â•‘      - High memory: Add RAM or tune application settings           â•‘
    â•‘      - Trending up: Plan scale-out before crisis                  â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    */
    {
      "datasource": "Prometheus",
      "description": "Host-level CPU and memory utilization (per node)",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "Utilization (%)",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 10,
            "gradientMode": "opacity",
            "hideFrom": {
              "tooltip": false,
              "viz": false,
              "legend": false
            },
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "max": 100,
          "min": 0,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 70
              },
              {
                "color": "red",
                "value": 90
              }
            ]
          },
          "unit": "percent"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 6
      },
      "id": 2,
      "options": {
        "legend": {
          "calcs": ["mean", "max", "last"],
          "displayMode": "table",
          "placement": "right"
        },
        "tooltip": {
          "mode": "multi"
        }
      },
      "pluginVersion": "8.0.0",
      "targets": [
        {
          "expr": "100 - (avg by (instance) (rate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
          "legendFormat": "{{instance}} CPU",
          "refId": "A"
        },
        {
          "expr": "(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100",
          "legendFormat": "{{instance}} Memory",
          "refId": "B"
        },
        {
          "expr": "70",
          "legendFormat": "CPU Warning (70%)",
          "refId": "C"
        },
        {
          "expr": "90",
          "legendFormat": "CPU Critical (90%)",
          "refId": "D"
        }
      ],
      "title": "ğŸ’» CPU & MEMORY UTILIZATION",
      "type": "timeseries"
    },

    /*
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘ PANEL 3: DISK USAGE & I/O PERFORMANCE                            â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘ Purpose: Monitor storage capacity and disk I/O health             â•‘
    â•‘ Data Source: Prometheus (node-exporter + block device metrics)   â•‘
    â•‘ Update Interval: 1-minute intervals                              â•‘
    â•‘ Visualization: Gauge charts (disk capacity) + bar chart (I/O)    â•‘
    â•‘                                                                   â•‘
    â•‘ Disk Space Monitoring:                                            â•‘
    â•‘ 1. Root filesystem (/)                                            â•‘
    â•‘    - Yellow: >75% capacity                                        â•‘
    â•‘    - Red: >90% capacity (will cause service disruptions)          â•‘
    â•‘                                                                   â•‘
    â•‘ 2. Data partition (/data)                                         â•‘
    â•‘    - Holds ClickHouse data, Kafka logs, MongoDB                   â•‘
    â•‘    - Yellow: >80% (growth trajectory concerning)                  â•‘
    â•‘    - Red: >95% (immediate action required)                        â•‘
    â•‘                                                                   â•‘
    â•‘ 3. Log partition (/var/log)                                       â•‘
    â•‘    - Application logs, system logs                                â•‘
    â•‘    - Should have cleanup policies (logrotate)                     â•‘
    â•‘    - Yellow: >70% (logs filling fast)                             â•‘
    â•‘                                                                   â•‘
    â•‘ Disk I/O Metrics:                                                 â•‘
    â•‘ - Read throughput (MB/s): Typical 50-200MB/s for analytics       â•‘
    â•‘ - Write throughput (MB/s): Typical 20-100MB/s for logging        â•‘
    â•‘ - Read latency (ms): Should be <5ms for HDDs, <1ms for SSDs      â•‘
    â•‘ - Write latency (ms): Should be <10ms                             â•‘
    â•‘ - IOPS: Random I/O operations/sec (affects database performance) â•‘
    â•‘                                                                   â•‘
    â•‘ Why: Storage capacity is fixed; need to know when to:            â•‘
    â•‘      - Archive old data (Kafka, ClickHouse)                       â•‘
    â•‘      - Add storage (expensive, plan ahead)                        â•‘
    â•‘      - Optimize compression (data warehouse)                      â•‘
    â•‘      - Investigate I/O bottlenecks (query slowness)               â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    */
    {
      "datasource": "Prometheus",
      "description": "Disk space usage and I/O performance metrics",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "custom": {
            "align": "auto",
            "displayMode": "color-background",
            "filterable": false
          },
          "mappings": [],
          "max": 100,
          "min": 0,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 75
              },
              {
                "color": "red",
                "value": 90
              }
            ]
          },
          "unit": "percent"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 6
      },
      "id": 3,
      "options": {
        "orientation": "auto",
        "showThresholdLabels": false,
        "showThresholdMarkers": true,
        "text": {}
      },
      "pluginVersion": "8.0.0",
      "targets": [
        {
          "expr": "(node_filesystem_size_bytes{mountpoint=\"/\"} - node_filesystem_avail_bytes{mountpoint=\"/\"}) / node_filesystem_size_bytes{mountpoint=\"/\"} * 100",
          "legendFormat": "/ (Root)",
          "refId": "A"
        },
        {
          "expr": "(node_filesystem_size_bytes{mountpoint=\"/data\"} - node_filesystem_avail_bytes{mountpoint=\"/data\"}) / node_filesystem_size_bytes{mountpoint=\"/data\"} * 100",
          "legendFormat": "/data (Storage)",
          "refId": "B"
        },
        {
          "expr": "(node_filesystem_size_bytes{mountpoint=\"/var/log\"} - node_filesystem_avail_bytes{mountpoint=\"/var/log\"}) / node_filesystem_size_bytes{mountpoint=\"/var/log\"} * 100",
          "legendFormat": "/var/log (Logs)",
          "refId": "C"
        }
      ],
      "title": "ğŸ’¾ DISK USAGE & I/O",
      "type": "gauge"
    },

    /*
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘ PANEL 4: DATA PIPELINE HEALTH (Kafka, ClickHouse, MongoDB)       â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘ Purpose: Monitor health of core data infrastructure               â•‘
    â•‘ Data Source: Prometheus (Kafka exporter, ClickHouse metrics)     â•‘
    â•‘ Update Interval: 30-second intervals                             â•‘
    â•‘ Visualization: Stat cards + line charts                          â•‘
    â•‘                                                                   â•‘
    â•‘ Kafka Metrics:                                                    â•‘
    â•‘ 1. Broker health                                                  â•‘
    â•‘    - Count: How many brokers online (target 3 for HA)             â•‘
    â•‘    - Leader balance: Are partitions evenly distributed?           â•‘
    â•‘                                                                   â•‘
    â•‘ 2. Message throughput                                             â•‘
    â•‘    - Bytes in/sec: Producers writing at expected rate             â•‘
    â•‘    - Bytes out/sec: Consumers reading (should be ~equal)          â•‘
    â•‘                                                                   â•‘
    â•‘ 3. Consumer lag                                                   â•‘
    â•‘    - telemetry-processing: Should be <10s (real-time pipeline)    â•‘
    â•‘    - daily-aggregation: Can lag 1-2h (batch processing)           â•‘
    â•‘    - Lag >lag_threshold = data not flowing to consumers           â•‘
    â•‘                                                                   â•‘
    â•‘ ClickHouse Metrics:                                               â•‘
    â•‘ 1. Query performance                                              â•‘
    â•‘    - QPS (queries/sec): Should be stable and predictable          â•‘
    â•‘    - Slow queries: Count with >5s duration                        â•‘
    â•‘    - Average latency: Spike indicates performance issues          â•‘
    â•‘                                                                   â•‘
    â•‘ 2. Replication lag                                                â•‘
    â•‘    - Should be <1s (seconds behind primary)                       â•‘
    â•‘    - >5s = replication bottleneck (investigate network/disk)      â•‘
    â•‘                                                                   â•‘
    â•‘ MongoDB Metrics:                                                  â•‘
    â•‘ 1. Replication status                                             â•‘
    â•‘    - Primary: Should be exactly 1                                 â•‘
    â•‘    - Secondary count: Should match configuration (2 for 3-node)   â•‘
    â•‘    - Arbiter: Optional node for breaking ties                     â•‘
    â•‘                                                                   â•‘
    â•‘ 2. Oplog entries                                                  â•‘
    â•‘    - Should be steady (number of changes per minute)              â•‘
    â•‘    - Spike = high change rate (normal during data import)         â•‘
    â•‘                                                                   â•‘
    â•‘ Why: Data pipeline health is critical. If any component is        â•‘
    â•‘      degraded, the entire analytics system will be affected.      â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    */
    {
      "datasource": "Prometheus",
      "description": "Data pipeline health: Kafka, ClickHouse, MongoDB metrics",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "Throughput",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 10,
            "gradientMode": "none",
            "hideFrom": {
              "tooltip": false,
              "viz": false,
              "legend": false
            },
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": true,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "max": null,
          "min": 0,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 9,
        "w": 12,
        "x": 0,
        "y": 14
      },
      "id": 4,
      "options": {
        "legend": {
          "calcs": ["mean", "max"],
          "displayMode": "table",
          "placement": "right"
        },
        "tooltip": {
          "mode": "multi"
        }
      },
      "pluginVersion": "8.0.0",
      "targets": [
        {
          "expr": "kafka_brokers_online",
          "legendFormat": "Kafka Brokers",
          "refId": "A"
        },
        {
          "expr": "rate(kafka_messages_in_per_sec[5m])",
          "legendFormat": "Kafka In (msg/s)",
          "refId": "B"
        },
        {
          "expr": "kafka_consumer_lag_seconds{group=\"telemetry-processing\"}",
          "legendFormat": "Telemetry Consumer Lag",
          "refId": "C"
        },
        {
          "expr": "clickhouse_query_duration_seconds_total",
          "legendFormat": "ClickHouse Query Latency",
          "refId": "D"
        },
        {
          "expr": "mongodb_replica_set_members",
          "legendFormat": "MongoDB Replica Members",
          "refId": "E"
        }
      ],
      "title": "ğŸ“Š DATA PIPELINE HEALTH",
      "type": "timeseries"
    },

    /*
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘ PANEL 5: CONTAINER & SERVICE STATUS                              â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘ Purpose: Track Docker container health and service availability   â•‘
    â•‘ Data Source: Docker API / cAdvisor metrics                        â•‘
    â•‘ Update Interval: 30-second intervals                             â•‘
    â•‘ Visualization: Table with status indicators                      â•‘
    â•‘                                                                   â•‘
    â•‘ Containers Monitored:                                             â•‘
    â•‘ 1. API Server (Python FastAPI)                                    â•‘
    â•‘    - Replicas: 2-4 (for high availability)                        â•‘
    â•‘    - Health: Readiness probe (HTTP GET /health)                   â•‘
    â•‘    - CPU: <100% per instance                                      â•‘
    â•‘    - Memory: <500MB per instance                                  â•‘
    â•‘    - Uptime: Should be >30 days (unless updated)                  â•‘
    â•‘                                                                   â•‘
    â•‘ 2. NiFi Flow Processor                                             â•‘
    â•‘    - Single instance (can be HA with load balancer)               â•‘
    â•‘    - Health: Check processor queue sizes                          â•‘
    â•‘    - Throughput: Documents processed per minute                   â•‘
    â•‘    - Memory: NiFi uses Java heap (4-8GB typical)                  â•‘
    â•‘                                                                   â•‘
    â•‘ 3. Kafka Brokers                                                  â•‘
    â•‘    - Count: 3 brokers for HA (one can fail, still operational)    â•‘
    â•‘    - Port: 9092 (internal), 29092 (Docker network)                â•‘
    â•‘    - JVM memory: ~4GB per broker                                  â•‘
    â•‘                                                                   â•‘
    â•‘ 4. ClickHouse Server                                              â•‘
    â•‘    - Single instance (could be HA cluster)                        â•‘
    â•‘    - Memory: Reserved for data caching (8-16GB)                   â•‘
    â•‘    - CPU: Should spike during query spikes                        â•‘
    â•‘                                                                   â•‘
    â•‘ 5. MongoDB                                                        â•‘
    â•‘    - Replica set (3 nodes: 1 primary + 2 secondaries)             â•‘
    â•‘    - Memory: Working set should be <available RAM                 â•‘
    â•‘                                                                   â•‘
    â•‘ 6. Redis Cache                                                    â•‘
    â•‘    - Single instance (could be sentinel for HA)                   â•‘
    â•‘    - Memory: Cache size should be tuned to working set            â•‘
    â•‘    - Eviction policy: Typically maxmemory-policy = allkeys-lru     â•‘
    â•‘                                                                   â•‘
    â•‘ 7. Grafana Dashboard UI                                           â•‘
    â•‘    - Single instance                                              â•‘
    â•‘    - Users online: Should be low-memory (stateless)               â•‘
    â•‘    - Requests: Spike during business hours                        â•‘
    â•‘                                                                   â•‘
    â•‘ 8. Prometheus Metrics Server                                      â•‘
    â•‘    - Single instance                                              â•‘
    â•‘    - Storage: TSDB database (grows ~1-2GB per day)                â•‘
    â•‘    - Scrape success: Should be ~99% (targets responsive)          â•‘
    â•‘                                                                   â•‘
    â•‘ Why: Container health is visibility into service availability.    â•‘
    â•‘      Crashed container = no service for that component.           â•‘
    â•‘      High memory = may be memory leak or misconfiguration.        â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    */
    {
      "datasource": "Prometheus",
      "description": "Container and service status with resource usage",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "custom": {
            "align": "auto",
            "displayMode": "color-background",
            "filterable": true
          },
          "mappings": [
            {
              "options": {
                "running": {
                  "color": "green",
                  "text": "Running"
                },
                "exited": {
                  "color": "red",
                  "text": "Stopped"
                },
                "restarting": {
                  "color": "orange",
                  "text": "Restarting"
                }
              },
              "type": "value"
            }
          ],
          "max": null,
          "min": null,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "short"
        },
        "overrides": [
          {
            "matcher": {
              "id": "byName",
              "options": "CPU"
            },
            "properties": [
              {
                "id": "unit",
                "value": "percent"
              },
              {
                "id": "custom.displayMode",
                "value": "color-background"
              }
            ]
          },
          {
            "matcher": {
              "id": "byName",
              "options": "Memory"
            },
            "properties": [
              {
                "id": "unit",
                "value": "megabytes"
              },
              {
                "id": "custom.displayMode",
                "value": "color-background"
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 9,
        "w": 12,
        "x": 12,
        "y": 14
      },
      "id": 5,
      "options": {
        "showHeader": true,
        "sortBy": [
          {
            "displayName": "Status",
            "desc": false
          }
        ]
      },
      "pluginVersion": "8.0.0",
      "targets": [
        {
          "format": "table",
          "instant": true,
          "queryType": "randomWalk",
          "refId": "A",
          "datasource": "Prometheus",
          "rawSql": "SELECT\n  container_name,\n  container_status,\n  ROUND(cpu_usage_percent, 1) as cpu,\n  ROUND(memory_usage_mb, 0) as memory,\n  ROUND(uptime_hours, 0) as uptime,\n  restart_count\nFROM container.status\nWHERE container_status != 'exited'\nORDER BY container_name"
        }
      ],
      "title": "ğŸ³ CONTAINER & SERVICE STATUS",
      "type": "table"
    },

    /*
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘ PANEL 6: NETWORK PERFORMANCE & LATENCY                           â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘ Purpose: Monitor network health between components                â•‘
    â•‘ Data Source: Prometheus (network metrics) + ping/traceroute       â•‘
    â•‘ Update Interval: 30-second intervals                             â•‘
    â•‘ Visualization: Line chart (latency) + heatmap (packet loss)      â•‘
    â•‘                                                                   â•‘
    â•‘ Network Metrics:                                                  â•‘
    â•‘ 1. API to Kafka latency                                           â•‘
    â•‘    - Should be <50ms (local network)                              â•‘
    â•‘    - If >200ms: Network congestion or DNS resolution issue        â•‘
    â•‘                                                                   â•‘
    â•‘ 2. Kafka to ClickHouse latency                                    â•‘
    â•‘    - Data pipeline latency                                        â•‘
    â•‘    - Should be <100ms                                             â•‘
    â•‘    - Important: Affects dashboard refresh lag                     â•‘
    â•‘                                                                   â•‘
    â•‘ 3. API to MongoDB latency                                         â•‘
    â•‘    - Document lookups in optimization data                        â•‘
    â•‘    - Should be <30ms                                              â•‘
    â•‘                                                                   â•‘
    â•‘ 4. Prometheus scrape latency                                      â•‘
    â•‘    - Time to scrape all targets                                   â•‘
    â•‘    - Should be <10s for 100+ targets                              â•‘
    â•‘    - If >15s: Some targets are slow or unresponsive               â•‘
    â•‘                                                                   â•‘
    â•‘ 5. Bandwidth usage                                                â•‘
    â•‘    - Ingress: Incoming data (should be stable)                    â•‘
    â•‘    - Egress: Outgoing data (Kafka replication, backups)           â•‘
    â•‘    - Alert if >80% of link capacity                               â•‘
    â•‘                                                                   â•‘
    â•‘ 6. Packet loss                                                    â•‘
    â•‘    - Should be 0%                                                 â•‘
    â•‘    - >0.1% indicates network quality issues                       â•‘
    â•‘    - >1%: Critical, investigate immediately                       â•‘
    â•‘                                                                   â•‘
    â•‘ Why: Network is critical glue between components.                 â•‘
    â•‘      High latency = data pipelines stall.                         â•‘
    â•‘      Packet loss = unreliable message delivery.                   â•‘
    â•‘      Bandwidth exhaustion = all services slow down.               â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    */
    {
      "datasource": "Prometheus",
      "description": "Network latency between components and bandwidth usage",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "Latency (ms)",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 10,
            "gradientMode": "none",
            "hideFrom": {
              "tooltip": false,
              "viz": false,
              "legend": false
            },
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "max": null,
          "min": 0,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 100
              },
              {
                "color": "red",
                "value": 200
              }
            ]
          },
          "unit": "ms"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 9,
        "w": 24,
        "x": 0,
        "y": 23
      },
      "id": 6,
      "options": {
        "legend": {
          "calcs": ["mean", "max"],
          "displayMode": "table",
          "placement": "bottom"
        },
        "tooltip": {
          "mode": "multi"
        }
      },
      "pluginVersion": "8.0.0",
      "targets": [
        {
          "expr": "probe_http_duration_seconds{job=\"api-kafka-latency\"} * 1000",
          "legendFormat": "API â†’ Kafka",
          "refId": "A"
        },
        {
          "expr": "probe_http_duration_seconds{job=\"kafka-clickhouse-latency\"} * 1000",
          "legendFormat": "Kafka â†’ ClickHouse",
          "refId": "B"
        },
        {
          "expr": "probe_http_duration_seconds{job=\"api-mongodb-latency\"} * 1000",
          "legendFormat": "API â†’ MongoDB",
          "refId": "C"
        },
        {
          "expr": "prometheus_sd_consul_rpc_duration_seconds * 1000",
          "legendFormat": "Prometheus Scrape Time",
          "refId": "D"
        }
      ],
      "title": "ğŸŒ NETWORK LATENCY & BANDWIDTH",
      "type": "timeseries"
    },

    /*
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘ PANEL 7: ALERT SUMMARY & INCIDENT TRACKER                        â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘ Purpose: Real-time alert management and incident response        â•‘
    â•‘ Data Source: Prometheus AlertManager                             â•‘
    â•‘ Update Interval: Real-time (webhook updates)                     â•‘
    â•‘ Visualization: Alert summary table                               â•‘
    â•‘                                                                   â•‘
    â•‘ Critical Alerts Configured:                                       â•‘
    â•‘ 1. Service Down Alerts                                            â•‘
    â•‘    - Kafka cluster any broker down                                â•‘
    â•‘    - ClickHouse unavailable                                       â•‘
    â•‘    - MongoDB primary down                                         â•‘
    â•‘    - Action: Immediate investigation + escalation                 â•‘
    â•‘                                                                   â•‘
    â•‘ 2. Resource Exhaustion Alerts                                      â•‘
    â•‘    - CPU >90% for 5 minutes                                        â•‘
    â•‘    - Memory >95%                                                  â•‘
    â•‘    - Disk >90% (requires immediate cleanup/expansion)             â•‘
    â•‘    - Action: Scale up or investigate spike                        â•‘
    â•‘                                                                   â•‘
    â•‘ 3. Data Pipeline Alerts                                           â•‘
    â•‘    - Consumer lag >30s for real-time pipeline                      â•‘
    â•‘    - ClickHouse replication lag >10s                              â•‘
    â•‘    - Prometheus scrape failures >10%                              â•‘
    â•‘    - Action: Check Kafka health, network connectivity             â•‘
    â•‘                                                                   â•‘
    â•‘ 4. Application Performance Alerts                                 â•‘
    â•‘    - API response time >1000ms (p99)                              â•‘
    â•‘    - Error rate >1%                                               â•‘
    â•‘    - Database connection pool exhausted                           â•‘
    â•‘    - Action: Check query performance, load                        â•‘
    â•‘                                                                   â•‘
    â•‘ 5. Security Alerts (optional)                                     â•‘
    â•‘    - Failed authentication attempts spike                         â•‘
    â•‘    - Unusual network traffic patterns                             â•‘
    â•‘    - Action: Review logs, investigate source                      â•‘
    â•‘                                                                   â•‘
    â•‘ Alert States:                                                     â•‘
    â•‘ - Firing: Alert condition is true (action required)               â•‘
    â•‘ - Resolved: Alert condition no longer true (investigation done)   â•‘
    â•‘ - Silenced: Maintenance window (temporary disable)                â•‘
    â•‘                                                                   â•‘
    â•‘ Alert Routing:                                                    â•‘
    â•‘ - Critical (P1): Page on-call engineer via PagerDuty              â•‘
    â•‘ - High (P2): Send to Slack #alerts channel                        â•‘
    â•‘ - Medium (P3): Log to incident tracker, daily digest              â•‘
    â•‘                                                                   â•‘
    â•‘ Why: On-call engineer needs rapid awareness of production         â•‘
    â•‘      issues. Alert fatigue is real: must be selective.            â•‘
    â•‘      Configure only high-impact, actionable alerts.               â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    */
    {
      "datasource": "Prometheus",
      "description": "Active alerts and incident summary",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "custom": {
            "align": "auto",
            "displayMode": "color-background",
            "filterable": true
          },
          "mappings": [
            {
              "options": {
                "Firing": {
                  "color": "red",
                  "text": "ğŸ”´ FIRING"
                },
                "Resolved": {
                  "color": "green",
                  "text": "âœ… Resolved"
                },
                "Silenced": {
                  "color": "orange",
                  "text": "ğŸ”‡ Silenced"
                }
              },
              "type": "value"
            }
          ],
          "max": null,
          "min": null,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "red",
                "value": null
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 9,
        "w": 24,
        "x": 0,
        "y": 32
      },
      "id": 7,
      "options": {
        "showHeader": true,
        "sortBy": [
          {
            "displayName": "Severity",
            "desc": true
          }
        ]
      },
      "pluginVersion": "8.0.0",
      "targets": [
        {
          "expr": "ALERTS",
          "format": "table",
          "instant": true,
          "refId": "A"
        }
      ],
      "title": "ğŸš¨ ACTIVE ALERTS & INCIDENTS",
      "type": "table"
    }
  ],
  "refresh": "30s",
  "schemaVersion": 35,
  "style": "dark",
  "tags": ["vertiflow", "infrastructure", "monitoring", "devops", "sre"],
  "templating": {
    "list": [
      {
        "current": {
          "selected": true,
          "text": "All",
          "value": "$__all"
        },
        "datasource": "Prometheus",
        "definition": "label_values(up, instance)",
        "description": null,
        "error": null,
        "hide": 0,
        "includeAll": true,
        "label": "Instance",
        "multi": true,
        "name": "instance",
        "options": [],
        "query": {
          "query": "label_values(up, instance)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 0,
        "tagValuesQuery": "",
        "tagsQuery": "",
        "type": "query"
      },
      {
        "current": {
          "selected": true,
          "text": "All",
          "value": "$__all"
        },
        "datasource": "Prometheus",
        "definition": "label_values(container_last_seen, container_name)",
        "description": null,
        "error": null,
        "hide": 0,
        "includeAll": true,
        "label": "Container",
        "multi": true,
        "name": "container",
        "options": [],
        "query": {
          "query": "label_values(container_last_seen, container_name)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 0,
        "tagValuesQuery": "",
        "tagsQuery": "",
        "type": "query"
      }
    ]
  },
  "time": {
    "from": "now-6h",
    "to": "now"
  },
  "timepicker": {
    "refresh_intervals": ["10s", "30s", "1m", "5m", "15m", "30m", "1h", "2h", "1d"]
  },
  "timezone": "UTC",
  "title": "VertiFlow System Health & Infrastructure Dashboard",
  "uid": "system-health",
  "version": 1
}

/*
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                            IMPLEMENTATION NOTES                              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                              â•‘
â•‘ INSTALLATION:                                                                â•‘
â•‘ 1. Save this file as: dashboards/grafana/04_system_health.json              â•‘
â•‘ 2. Import to Grafana: Home â†’ Dashboards â†’ Import â†’ Paste JSON               â•‘
â•‘ 3. Configure data sources:                                                   â•‘
â•‘    - Prometheus: Infrastructure metrics (node-exporter, cAdvisor)            â•‘
â•‘    - AlertManager: Real-time alert status                                    â•‘
â•‘                                                                              â•‘
â•‘ DATA DEPENDENCIES:                                                           â•‘
â•‘ 1. Host Metrics (node-exporter)                                              â•‘
â•‘    â”œâ”€ Source: Prometheus node-exporter on each host                          â•‘
â•‘    â”œâ”€ Metrics: cpu, memory, disk, network, processes                         â•‘
â•‘    â””â”€ Update: 15-30 second intervals                                         â•‘
â•‘                                                                              â•‘
â•‘ 2. Container Metrics (cAdvisor / Docker)                                     â•‘
â•‘    â”œâ”€ Source: Docker stats API / cAdvisor                                    â•‘
â•‘    â”œâ”€ Metrics: container CPU, memory, I/O, network per container             â•‘
â•‘    â””â”€ Update: 30-60 second intervals                                         â•‘
â•‘                                                                              â•‘
â•‘ 3. Service-Specific Metrics                                                  â•‘
â•‘    â”œâ”€ Kafka: JMX exporter for broker metrics                                 â•‘
â•‘    â”œâ”€ ClickHouse: Native HTTP metrics endpoint                               â•‘
â•‘    â”œâ”€ MongoDB: MongoDB exporter                                              â•‘
â•‘    â””â”€ Redis: Redis exporter                                                  â•‘
â•‘                                                                              â•‘
â•‘ 4. Alert Rules                                                               â•‘
â•‘    â”œâ”€ Source: prometheus/alerts.yml                                          â•‘
â•‘    â”œâ”€ Types: Service down, resource exhaustion, pipeline health              â•‘
â•‘    â””â”€ Update: Real-time (webhook from AlertManager)                          â•‘
â•‘                                                                              â•‘
â•‘ RECOMMENDED ALERT RULES (prometheus/alerts.yml):                             â•‘
â•‘                                                                              â•‘
â•‘ # Service Down Alerts                                                        â•‘
â•‘ - alert: KafkaClusterDown                                                    â•‘
â•‘   expr: count(up{job="kafka"}) < 3                                           â•‘
â•‘   for: 2m                                                                    â•‘
â•‘   annotations:                                                               â•‘
â•‘     severity: critical                                                       â•‘
â•‘     summary: "Kafka cluster degraded"                                        â•‘
â•‘     description: "Fewer than 3 brokers online"                               â•‘
â•‘                                                                              â•‘
â•‘ # Resource Exhaustion                                                        â•‘
â•‘ - alert: HighCPUUsage                                                        â•‘
â•‘   expr: (1 - avg(rate(node_cpu_seconds_total{mode="idle"}[5m]))) > 0.9      â•‘
â•‘   for: 5m                                                                    â•‘
â•‘   annotations:                                                               â•‘
â•‘     severity: warning                                                        â•‘
â•‘     summary: "High CPU utilization"                                          â•‘
â•‘                                                                              â•‘
â•‘ - alert: HighMemoryUsage                                                     â•‘
â•‘   expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) > 0.95
â•‘   for: 3m                                                                    â•‘
â•‘   annotations:                                                               â•‘
â•‘     severity: warning                                                        â•‘
â•‘     summary: "Memory approaching exhaustion"                                 â•‘
â•‘                                                                              â•‘
â•‘ - alert: DiskFull                                                            â•‘
â•‘   expr: node_filesystem_avail_bytes{mountpoint="/"} < 2*1024*1024*1024      â•‘
â•‘   for: 5m                                                                    â•‘
â•‘   annotations:                                                               â•‘
â•‘     severity: critical                                                       â•‘
â•‘     summary: "Disk space critical"                                           â•‘
â•‘                                                                              â•‘
â•‘ # Data Pipeline Health                                                       â•‘
â•‘ - alert: KafkaConsumerLagHigh                                                â•‘
â•‘   expr: kafka_consumer_lag_seconds{group="telemetry-processing"} > 30        â•‘
â•‘   for: 5m                                                                    â•‘
â•‘   annotations:                                                               â•‘
â•‘     severity: warning                                                        â•‘
â•‘     summary: "Consumer lag exceeded threshold"                               â•‘
â•‘                                                                              â•‘
â•‘ - alert: ClickHouseReplicationLag                                             â•‘
â•‘   expr: clickhouse_replica_internal_replication_delay_seconds > 10           â•‘
â•‘   for: 3m                                                                    â•‘
â•‘   annotations:                                                               â•‘
â•‘     severity: warning                                                        â•‘
â•‘     summary: "ClickHouse replica lagging"                                    â•‘
â•‘                                                                              â•‘
â•‘ # Application Performance                                                    â•‘
â•‘ - alert: HighAPILatency                                                      â•‘
â•‘   expr: histogram_quantile(0.99, rate(http_request_duration_seconds[5m])) > 1
â•‘   for: 5m                                                                    â•‘
â•‘   annotations:                                                               â•‘
â•‘     severity: warning                                                        â•‘
â•‘     summary: "API response time high"                                        â•‘
â•‘                                                                              â•‘
â•‘ DASHBOARD USAGE:                                                             â•‘
â•‘ 1. Daily Check: Review Panel 1 (status cards) each morning                   â•‘
â•‘ 2. Escalation: If ANY red card â†’ immediate investigation                     â•‘
â•‘ 3. Capacity Planning: Check CPU/Memory/Disk trends monthly                   â•‘
â•‘ 4. Incident Response:                                                        â•‘
â•‘    - Jump to Panel 2 (CPU/Memory) to find resource hog                       â•‘
â•‘    - Jump to Panel 4 (Pipeline) to diagnose data flow issue                   â•‘
â•‘    - Jump to Panel 7 (Alerts) to understand what triggered                   â•‘
â•‘ 5. Performance Tuning: Review Panel 6 (Latency) weekly                       â•‘
â•‘                                                                              â•‘
â•‘ ON-CALL RUNBOOK:                                                             â•‘
â•‘ Alert Fired â†’ Check Dashboard â†’ Identify Root Cause â†’ Take Action            â•‘
â•‘                                                                              â•‘
â•‘ Service Down (Red in Panel 1)?                                               â•‘
â•‘   â†’ Jump to Panel 5 (Containers)                                             â•‘
â•‘   â†’ Find container with status "Stopped"                                     â•‘
â•‘   â†’ SSH to host: docker restart <container_name>                             â•‘
â•‘   â†’ Verify it returns to "Running" status                                    â•‘
â•‘   â†’ Investigation: Check logs for error: docker logs <container_name>        â•‘
â•‘                                                                              â•‘
â•‘ High CPU (Red in Panel 2)?                                                   â•‘
â•‘   â†’ Jump to Panel 5 (Containers)                                             â•‘
â•‘   â†’ Find container with highest CPU %                                        â•‘
â•‘   â†’ SSH to host: docker stats --no-stream | grep <container>                 â•‘
â•‘   â†’ Check application logs for runaway process                               â•‘
â•‘   â†’ Possible actions:                                                        â•‘
â•‘     - Restart container (often fixes memory leaks)                           â•‘
â•‘     - Increase CPU allocation (vertical scale)                               â•‘
â•‘     - Scale out (add more replicas for stateless services)                   â•‘
â•‘                                                                              â•‘
â•‘ Consumer Lag High (Panel 4)?                                                 â•‘
â•‘   â†’ Check if Kafka brokers are up (Panel 1)                                  â•‘
â•‘   â†’ Check Kafka throughput (Panel 4, Kafka In msg/s)                         â•‘
â•‘   â†’ If throughput spike: likely consumer can't keep up                       â•‘
â•‘   â†’ Scale consumer: increase parallelism in config                           â•‘
â•‘   â†’ If no throughput spike: consumer likely crashed                          â•‘
â•‘   â†’ Restart consumer application                                             â•‘
â•‘                                                                              â•‘
â•‘ Disk Full (Panel 3)?                                                         â•‘
â•‘   â†’ SSH to host: df -h to see usage                                          â•‘
â•‘   â†’ Find largest directories: du -sh /var/log /data/*                        â•‘
â•‘   â†’ Options:                                                                 â•‘
â•‘     - Archive old Kafka logs: kafka-log-dirs delete                          â•‘
â•‘     - Cleanup old ClickHouse parts: ALTER TABLE ... DELETE                   â•‘
â•‘     - Rotate application logs: logrotate trigger                             â•‘
â•‘     - Expand storage: add volume to /data partition                          â•‘
â•‘                                                                              â•‘
â•‘ ACCESS CONTROL:                                                              â•‘
â•‘ - DevOps: Full read/write access                                             â•‘
â•‘ - SRE: Full read/write access                                                â•‘
â•‘ - Platform engineers: Read-only (learn operations)                           â•‘
â•‘ - Management: Alert summary view only                                        â•‘
â•‘                                                                              â•‘
â•‘ MAINTENANCE SCHEDULE:                                                        â•‘
â•‘ - Daily: Check Panel 1 status, review Panel 7 alerts                         â•‘
â•‘ - Weekly: Capacity trend analysis (Panels 2, 3)                              â•‘
â•‘ - Monthly: Performance baselines, alert threshold tuning                      â•‘
â•‘ - Quarterly: Disaster recovery drill (simulate failures)                     â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DOCUMENT FOOTER:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TICKET: TICKET-122
ASSIGNED TO: @Imrane (DevOps Lead)
TEAM: @Imrane (infrastructure/monitoring), @Mouhammed (platform engineering),
      @Mounir (architecture oversight)

CONTACT FOR QUESTIONS:
- @Imrane: Infrastructure health, alert rules, capacity planning, incident response
- @Mouhammed: Data pipeline configuration, service metrics, troubleshooting
- @Mounir: Dashboard architecture, long-term infrastructure strategy

PROJECT: VertiFlow Data Platform - Intelligent Vertical Farming
STATUS: Production Release
CLASSIFICATION: Technical - Internal
REPOSITORY: J-Mounir/test-projet-agri (GitHub)

LAST UPDATED: 2026-01-03
NEXT REVIEW: 2026-02-03 (Monthly)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
*/
